"""
This type stub file was generated by pyright.
"""

import os
import numpy as np
from collections.abc import Collection
from typing import Iterable, Mapping, Optional, Union
from tensorflow.core.protobuf import meta_graph_pb2
from tensorflow.python.client import session
from tensorflow.python.types import core
from tensorflow.python.util import tf_export

"""Defines types required for representative datasets for quantization."""
RepresentativeSample = Mapping[str, core.TensorLike]
RepresentativeDataset = Iterable[RepresentativeSample]
RepresentativeDatasetMapping = Mapping[str, RepresentativeDataset]
RepresentativeDatasetOrMapping = Union[RepresentativeDataset, RepresentativeDatasetMapping]
_RepresentativeDataSample = ...
_RepresentativeDatasetFile = ...
class RepresentativeDatasetSaver:
  """Representative dataset saver.

  Exposes a single method `save` that saves the provided representative dataset
  into files.

  This is useful when you would like to keep a snapshot of your representative
  dataset at a file system or when you need to pass the representative dataset
  as files.
  """
  def save(self, representative_dataset: RepresentativeDatasetMapping) -> Mapping[str, _RepresentativeDatasetFile]:
    """Saves the representative dataset.

    Args:
      representative_dataset: RepresentativeDatasetMapping which is a
        signature_def_key -> representative dataset mapping.
    """
    ...
  


@tf_export.tf_export('quantization.experimental.TfRecordRepresentativeDatasetSaver')
class TfRecordRepresentativeDatasetSaver(RepresentativeDatasetSaver):
  """Representative dataset saver in TFRecord format.

  Saves representative datasets for quantization calibration in TFRecord format.
  The samples are serialized as `RepresentativeDataSample`.

  The `save` method return a signature key to `RepresentativeDatasetFile` map,
  which can be used for QuantizationOptions.

  Example usage:

  ```python
  # Creating the representative dataset.
  representative_dataset = [{"input": tf.random.uniform(shape=(3, 3))}
                        for _ in range(256)]

  # Saving to a TFRecord file.
  dataset_file_map = (
    tf.quantization.experimental.TfRecordRepresentativeDatasetSaver(
          path_map={'serving_default': '/tmp/representative_dataset_path'}
      ).save({'serving_default': representative_dataset})
  )

  # Using in QuantizationOptions.
  quantization_options = tf.quantization.experimental.QuantizationOptions(
      signature_keys=['serving_default'],
      representative_datasets=dataset_file_map,
  )
  tf.quantization.experimental.quantize_saved_model(
      '/tmp/input_model',
      '/tmp/output_model',
      quantization_options=quantization_options,
  )
  ```
  """
  def __init__(self, path_map: Mapping[str, os.PathLike[str]], expected_input_key_map: Optional[Mapping[str, Collection[str]]] = ...) -> None:
    """Initializes TFRecord represenatative dataset saver.

    Args:
      path_map: Signature def key -> path mapping. Each path is a TFRecord file
        to which a `RepresentativeDataset` is saved. The signature def keys
        should be a subset of the `SignatureDef` keys of the
        `representative_dataset` argument of the `save()` call.
      expected_input_key_map: Signature def key -> expected input keys. If set,
        validate that the sample has same set of input keys before saving.

    Raises:
      KeyError: If path_map and expected_input_key_map have different keys.
    """
    ...
  
  def save(self, representative_dataset: RepresentativeDatasetMapping) -> Mapping[str, _RepresentativeDatasetFile]:
    """Saves the representative dataset.

    Args:
      representative_dataset: Signature def key -> representative dataset
        mapping. Each dataset is saved in a separate TFRecord file whose path
        matches the signature def key of `path_map`.

    Raises:
      ValueError: When the signature def key in `representative_dataset` is not
      present in the `path_map`.

    Returns:
      A map from signature key to the RepresentativeDatasetFile instance
      contains the path to the saved file.
    """
    ...
  


class RepresentativeDatasetLoader:
  """Representative dataset loader.

  Exposes the `load` method that loads the representative dataset from files.
  """
  def load(self) -> RepresentativeDatasetMapping:
    """Loads the representative datasets.

    Returns:
      representative dataset mapping: A loaded signature def key ->
      representative mapping.
    """
    ...
  


class TfRecordRepresentativeDatasetLoader(RepresentativeDatasetLoader):
  """TFRecord representative dataset loader.

  Loads representative dataset stored in TFRecord files.
  """
  def __init__(self, dataset_file_map: Mapping[str, _RepresentativeDatasetFile]) -> None:
    """Initializes TFRecord represenatative dataset loader.

    Args:
      dataset_file_map: Signature key -> `RepresentativeDatasetFile` mapping.

    Raises:
      DecodeError: If the sample is not RepresentativeDataSample.
    """
    ...
  
  def load(self) -> RepresentativeDatasetMapping:
    """Loads the representative datasets.

    Returns:
      representative dataset mapping: A signature def key -> representative
      mapping. The loader loads `RepresentativeDataset` for each path in
      `self.dataset_file_map` and associates the loaded dataset to the
      corresponding signature def key.
    """
    ...
  


def replace_tensors_by_numpy_ndarrays(repr_ds: RepresentativeDataset, sess: session.Session) -> RepresentativeDataset:
  """Replaces tf.Tensors in samples by their evaluated numpy arrays.

  Note: This should be run in graph mode (default in TF1) only.

  Args:
    repr_ds: Representative dataset to replace the tf.Tensors with their
      evaluated values. `repr_ds` is iterated through, so it may not be reusable
      (e.g. if it is a generator object).
    sess: Session instance used to evaluate tf.Tensors.

  Returns:
    The new representative dataset where each tf.Tensor is replaced by its
    evaluated numpy ndarrays.
  """
  ...

def get_num_samples(repr_ds: RepresentativeDataset) -> Optional[int]:
  """Returns the number of samples if known.

  Args:
    repr_ds: Representative dataset.

  Returns:
    Returns the total number of samples in `repr_ds` if it can be determined
    without iterating the entier dataset. Returns None iff otherwise. When it
    returns None it does not mean the representative dataset is infinite or it
    is malformed; it simply means the size cannot be determined without
    iterating the whole dataset.
  """
  ...

def create_feed_dict_from_input_data(input_data: RepresentativeSample, signature_def: meta_graph_pb2.SignatureDef) -> Mapping[str, np.ndarray]:
  """Constructs a feed_dict from input data.

  Note: This function should only be used in graph mode.

  This is a helper function that converts an 'input key -> input value' mapping
  to a feed dict. A feed dict is an 'input tensor name -> input value' mapping
  and can be directly passed to the `feed_dict` argument of `sess.run()`.

  Args:
    input_data: Input key -> input value mapping. The input keys should match
      the input keys of `signature_def`.
    signature_def: A SignatureDef representing the function that `input_data` is
      an input to.

  Returns:
    Feed dict, which is intended to be used as input for `sess.run`. It is
    essentially a mapping: input tensor name -> input value. Note that the input
    value in the feed dict is not a `Tensor`.
  """
  ...

