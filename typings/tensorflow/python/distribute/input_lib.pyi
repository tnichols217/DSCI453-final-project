"""
This type stub file was generated by pyright.
"""

from tensorflow.python.framework import composite_tensor, type_spec
from tensorflow.python.types import distribute as distribute_types
from tensorflow.python.util.compat import collections_abc

"""Various classes representing distributed inputs."""
_distributed_dataset_initialization_time_milliseconds = ...
_distributed_dataset_from_function_initialization_time_milliseconds = ...
def get_iterator_spec_from_dataset(strategy, dataset): # -> DistributedIteratorSpec | IteratorSpec:
  """Returns an iterator spec from dataset function.

  This function constructs type spec for iterator obtained from
  iter(dataset).

  Args:
    strategy: a `tf.distribute.Strategy` object, used to run all-reduce to
        handle last partial batch.
    dataset: A tf.data.Dataset instance. If using a function that returns a
      tf.data.Dataset instance, pass dataset_fn.structured_outputs.

  Returns:
    A type_spec for iterator for dataset instance.

  """
  ...

class InputWorkers:
  """A 1-to-many mapping from input worker devices to compute devices."""
  def __init__(self, worker_device_pairs, canonicalize_devices=...) -> None:
    """Initialize an `InputWorkers` object.

    Args:
      worker_device_pairs: A sequence of pairs: `(input device, a tuple of
        compute devices fed by that input device)`.
      canonicalize_devices: Whether to canonicalize devices for workers fully or
        partially. If False, it will partially canonicalize devices by removing
        job and task.
    """
    ...
  
  @property
  def num_workers(self): # -> int:
    ...
  
  @property
  def worker_devices(self): # -> tuple[Any, ...]:
    ...
  
  def compute_devices_for_worker(self, worker_index): # -> tuple[Any | str, ...]:
    ...
  
  def __repr__(self): # -> str:
    ...
  
  def serialize(self): # -> tuple[Any, bool]:
    ...
  
  def deserialize(self, serialized): # -> InputWorkers:
    ...
  


class DistributedIteratorBase(collections_abc.Iterator, distribute_types.DistributedIteratorInterface):
  """Common implementation for all input iterators."""
  def __init__(self, input_workers, iterators, strategy, cardinality, enable_get_next_as_optional, replica_order=...) -> None:
    ...
  
  def next(self): # -> list[list[Any] | Any | tuple[list[Any] | Any | Mapping[Any, Any] | DistributedVariable | CompositeTensor | PerReplica, ...] | Mapping[Any, Any] | DistributedVariable | CompositeTensor | PerReplica] | tuple[list[Any] | Any | Mapping[Any, Any] | DistributedVariable | CompositeTensor | PerReplica, ...] | Mapping[Any, Any] | DistributedVariable | CompositeTensor | PerReplica | defaultdict[Any, Any] | Any | list[Any] | tuple[Any, ...] | None:
    ...
  
  def __next__(self): # -> list[list[Any] | Any | tuple[list[Any] | Any | Mapping[Any, Any] | DistributedVariable | CompositeTensor | PerReplica, ...] | Mapping[Any, Any] | DistributedVariable | CompositeTensor | PerReplica] | tuple[list[Any] | Any | Mapping[Any, Any] | DistributedVariable | CompositeTensor | PerReplica, ...] | Mapping[Any, Any] | DistributedVariable | CompositeTensor | PerReplica | defaultdict[Any, Any] | Any | list[Any] | tuple[Any, ...] | None:
    ...
  
  def __iter__(self): # -> Self:
    ...
  
  def get_next_as_optional(self): # -> _OptionalImpl | defaultdict[Any, Any] | Any | list[Any] | tuple[Any, ...] | None:
    ...
  
  def get_next(self, name=...): # -> list[list[Any] | Any | tuple[list[Any] | Any | Mapping[Any, Any] | DistributedVariable | CompositeTensor | PerReplica, ...] | Mapping[Any, Any] | DistributedVariable | CompositeTensor | PerReplica] | tuple[list[Any] | Any | Mapping[Any, Any] | DistributedVariable | CompositeTensor | PerReplica, ...] | Mapping[Any, Any] | DistributedVariable | CompositeTensor | PerReplica | defaultdict[Any, Any] | Any | list[Any] | tuple[Any, ...] | None:
    """Returns the next input from the iterator for all replicas."""
    ...
  


class DistributedDatasetAndIteratorSpec(type_spec.TypeSpec):
  """Common Type specification for `DistributedDataset and DistributedDatasetsFromFunction."""
  __slots__ = ...
  def __init__(self, input_workers, element_spec, strategy, options, cardinality=..., enable_get_next_as_optional=..., replica_order=...) -> None:
    ...
  
  def sanity_check_type(self, other): # -> None:
    """Returns the most specific TypeSpec compatible with `self` and `other`.

    Args:
      other: A `TypeSpec`.

    Raises:
      ValueError: If there is no TypeSpec that is compatible with both `self`
        and `other`.
    """
    ...
  
  def is_subtype_of(self, other): # -> bool:
    """Returns True if `self` is subtype of `other`.

    Args:
      other: A `TypeSpec`.
    """
    ...
  
  def most_specific_common_supertype(self, others): # -> Self | None:
    """Returns the most specific supertype of `self` and `others`.

    Args:
      others: A Sequence of `TypeSpec`.

    Returns `None` if a supertype does not exist.
    """
    ...
  


class DistributedIteratorSpec(DistributedDatasetAndIteratorSpec):
  """Type specification for `DistributedIterator`."""
  @property
  def value_type(self): # -> type[DistributedIterator]:
    ...
  
  @staticmethod
  def from_value(value): # -> DistributedIteratorSpec:
    ...
  


class DistributedIterator(DistributedIteratorBase, composite_tensor.CompositeTensor):
  """Input Iterator for a distributed dataset."""
  def __init__(self, input_workers=..., iterators=..., strategy=..., components=..., element_spec=..., cardinality=..., enable_get_next_as_optional=..., options=..., replica_order=...) -> None:
    ...
  
  @property
  def element_spec(self): # -> defaultdict[Any, Any] | Any | list[Any] | object | None:
    ...
  


class _IterableInput(collections_abc.Iterable, distribute_types.DistributedDatasetInterface):
  """Base class for iterable inputs for distribution strategies."""
  def __init__(self, input_workers) -> None:
    ...
  
  def __iter__(self):
    ...
  
  def reduce(self, initial_state, reduce_fn): # -> Any:
    """Execute a `reduce_fn` over all the elements of the input."""
    ...
  


class DistributedDatasetSpec(DistributedDatasetAndIteratorSpec):
  """Type specification for `DistributedDataset."""
  @property
  def value_type(self): # -> type[DistributedDataset]:
    ...
  
  @staticmethod
  def from_value(value): # -> DistributedDatasetSpec:
    ...
  


class DistributedDataset(_IterableInput, composite_tensor.CompositeTensor):
  """Distributed dataset that supports prefetching to multiple devices."""
  def __init__(self, input_workers, strategy, dataset=..., num_replicas_in_sync=..., input_context=..., components=..., element_spec=..., enable_get_next_as_optional=..., build=..., options=..., replica_order=...) -> None:
    """Distribute the dataset on all workers.

    If `num_replicas_in_sync` is not None, we split each batch of the dataset
    into `num_replicas_in_sync` smaller batches, to be distributed among that
    worker's replicas, so that the batch size for a global step (across all
    workers and replicas) is as expected.

    Args:
      input_workers: an `InputWorkers` object.
      strategy: a `tf.distribute.Strategy` object, used to run all-reduce to
        handle last partial batch.
      dataset: `tf.data.Dataset` that will be used as the input source. Either
        dataset or components field should be passed when constructing
        DistributedDataset. Use this when contructing DistributedDataset from a
        new `tf.data.Dataset`. Use components when constructing using
        DistributedDatasetSpec.
      num_replicas_in_sync: Optional integer. If this is not None, the value is
        used to decide how to rebatch datasets into smaller batches so that the
        total batch size for each step (across all workers and replicas) adds up
        to `dataset`'s batch size.
      input_context: `InputContext` for sharding. Only pass this in for between
        graph multi-worker cases where there is only one `input_worker`. In
        these cases, we will shard based on the `input_pipeline_id` and
        `num_input_pipelines` in the `InputContext`.
      components: datasets when DistributedDataset is constructed from
        DistributedDatasetSpec. Either field dataset or components should be
        passed.
      element_spec: element spec for DistributedDataset when constructing from
        DistributedDatasetSpec. This will be used to set the element_spec for
        DistributedDataset and verified against element_spec from components.
      enable_get_next_as_optional: this is required when components is passed
        instead of dataset.
      build: whether to build underlying datasets when this object is created.
        This is only useful for `ParameterServerStrategy` now.
      options: `tf.distribute.InputOptions` used to control options on how this
        dataset is distributed.
      replica_order: the order of the replicas, which will be used to reorder
        the iterators to match the device order.
    """
    ...
  
  def build(self, dataset_to_replace=...): # -> None:
    ...
  
  def auto_shard(self, num_shards, shard_ix): # -> DistributedDataset:
    ...
  
  @property
  def cardinality(self): # -> int:
    ...
  
  def __iter__(self): # -> DistributedIterator:
    ...
  
  @property
  def element_spec(self): # -> defaultdict[Any, Any] | Any | list[Any] | object | None:
    """The type specification of an element of this dataset."""
    ...
  


class DistributedDatasetsFromFunctionSpec(DistributedDatasetAndIteratorSpec):
  """Type specification for `DistributedDatasetsFromFunction."""
  @property
  def value_type(self): # -> type[DistributedDatasetsFromFunction]:
    ...
  
  @staticmethod
  def from_value(value): # -> DistributedDatasetsFromFunctionSpec:
    ...
  


class DistributedDatasetsFromFunction(_IterableInput, composite_tensor.CompositeTensor):
  """Inputs created from dataset function."""
  def __init__(self, input_workers, strategy, input_contexts=..., dataset_fn=..., options=..., components=..., element_spec=..., build=..., replica_order=...) -> None:
    """Makes an iterable from datasets created by the given function.

    Args:
      input_workers: an `InputWorkers` object.
      strategy: a `tf.distribute.Strategy` object, used to run all-reduce to
        handle last partial batch.
      input_contexts: A list of `InputContext` instances to be passed to call(s)
        to `dataset_fn`. Length and order should match worker order in
        `worker_device_pairs`.
      dataset_fn: A function that returns a `Dataset` given an `InputContext`.
        Either dataset_fn or components should be passed to construct
        DistributedDatasetsFromFunction. Use this when constructing
        DistributedDataset using a function. Use components when constructing
        using DistributedDatasetsFromFunctionSpec.
      options: `tf.distribute.InputOptions` used to control options on how this
        dataset is distributed.
      components: datasets when DistributedDatasetsFromFunction is constructed
        from DistributedDatasetsFromFunctionSpec. Only one of dataset or
        components should be passed.
      element_spec: element spec for DistributedDataset when constructing from
        DistributedDatasetSpec. This will be used to set the element_spec for
        DistributedDatasetsFromFunctionSpec and verified against element_spec
        from components.
      build: whether to build underlying datasets when this object is created.
        This is only useful for `ParameterServerStrategy` now.
      replica_order: the order of the replicas, which will be used to reorder
        the iterators to match the device order.
    """
    ...
  
  def build(self): # -> None:
    ...
  
  def auto_shard(self, num_shards, shard_ix): # -> DistributedDatasetsFromFunction:
    ...
  
  @property
  def cardinality(self): # -> int:
    ...
  
  def __iter__(self): # -> DistributedIterator:
    ...
  
  @property
  def element_spec(self): # -> defaultdict[Any, Any] | Any | list[Any] | object | None:
    """The type specification of an element of this dataset."""
    ...
  


class _SingleWorkerDatasetIteratorBase:
  """Iterator for a single `tf.data.Dataset`."""
  def __init__(self, dataset, worker, devices, options=...) -> None:
    """Create iterator for the `dataset` to fetch data to worker's `devices` .

    A `MultiDeviceIterator`  or `OwnedMultiDeviceIterator` is used to prefetch
    input to the devices on the given worker.

    Args:
      dataset: A `tf.data.Dataset` instance.
      worker: Worker on which ops should be created.
      devices: Distribute data from `dataset` to these devices.
      options: options.
    """
    ...
  
  def get_next(self, device, name=...):
    """Get next element for the given device."""
    ...
  
  def get_next_as_list(self, name=...): # -> list[Any]:
    """Get next element from the underlying iterator.

    Runs the iterator get_next() within a device scope. Since this doesn't use
    get_next_as_optional(), it is considerably faster than get_next_as_list(),
    but it raises EOFError if any of the device doesn't get any data.

    Args:
      name: not used.

    Returns:
      A list consisting of the next data from each device.
    """
    ...
  
  def get_next_as_optional_list(self): # -> list[Any]:
    ...
  


class _SingleWorkerDatasetIteratorSpec(type_spec.TypeSpec):
  """Type specification for `_SingleWorkerOwnedDatasetIterator`."""
  __slots__ = ...
  def __init__(self, worker, devices, element_spec, options, canonicalize_devices=...) -> None:
    ...
  
  @property
  def value_type(self): # -> type[_SingleWorkerOwnedDatasetIterator]:
    ...
  
  @staticmethod
  def from_value(value): # -> _SingleWorkerDatasetIteratorSpec:
    ...
  


class _SingleWorkerOwnedDatasetIterator(_SingleWorkerDatasetIteratorBase, composite_tensor.CompositeTensor):
  """Iterator for a DistributedDataset instance."""
  def __init__(self, dataset=..., worker=..., devices=..., components=..., element_spec=..., options=..., canonicalize_devices=...) -> None:
    """Create iterator for the `dataset` to fetch data to worker's `devices` .

    `OwnedMultiDeviceIterator` is used to prefetch input to the devices on the
    given worker. The lifetime of this iterator is tied to the encompassing
    python object. Once we go out of scope of the python object or return from
    a tf.function the underlying iterator resource is deleted.

    Args:
      dataset: A `tf.data.Dataset` instance.
      worker: Worker on which ops should be created.
      devices: Distribute data from `dataset` to these devices.
      components: Tensor components to construct the
        _SingleWorkerOwnedDatasetIterator from.
      element_spec: A nested structure of `TypeSpec` objects that represents the
      type specification of elements of the iterator.
      options: `tf.distribute.InputOptions` used to control options on how this
      dataset is distributed.
      canonicalize_devices: Whether to canonicalize devices for workers fully or
      partially. If False, it will partially canonicalize devices by removing
      job and task.
    """
    ...
  
  @property
  def element_spec(self):
    ...
  
  @property
  def output_classes(self): # -> defaultdict[Any, Any] | Any | list[Any] | object | None:
    """Returns the class of each component of an element of this iterator.

    The expected values are `tf.Tensor` and `tf.SparseTensor`.

    Returns:
      A nested structure of Python `type` objects corresponding to each
      component of an element of this dataset.
    """
    ...
  
  @property
  def output_shapes(self): # -> defaultdict[Any, Any] | Any | list[Any] | object | None:
    """Returns the shape of each component of an element of this iterator.

    Returns:
      A nested structure of `tf.TensorShape` objects corresponding to each
      component of an element of this dataset.
    """
    ...
  
  @property
  def output_types(self): # -> defaultdict[Any, Any] | Any | list[Any] | object | None:
    """Returns the type of each component of an element of this iterator.

    Returns:
      A nested structure of `tf.DType` objects corresponding to each component
      of an element of this dataset.
    """
    ...
  


class MultiStepContext:
  """A context object that can be used to capture things when running steps.

  This context object is useful when running multiple steps at a time using the
  `experimental_run_steps_on_iterator` API. For e.g. it allows the user's step
  function to specify which outputs to emit at what frequency. Currently it
  supports capturing output from the last step, as well as capturing non tensor
  outputs.  In the future it will be augmented to support other use cases such
  as output each N steps.
  """
  def __init__(self) -> None:
    """Initialize an output context.

    Returns:
      A context object.
    """
    ...
  
  @property
  def last_step_outputs(self): # -> dict[Any, Any]:
    """A dictionary consisting of outputs to be captured on last step.

    Keys in the dictionary are names of tensors to be captured, as specified
    when `set_last_step_output` is called.
    Values in the dictionary are the tensors themselves. If
    `set_last_step_output` was called with a `reduce_op` for this output,
    then the value is the reduced value.

    Returns:
      A dictionary with last step outputs.
    """
    ...
  
  def set_last_step_output(self, name, output, reduce_op=...): # -> None:
    """Set `output` with `name` to be outputted from the last step.

    Args:
      name: String, name to identify the output. Doesn't need to match tensor
        name.
      output: The tensors that should be outputted with `name`. See below for
        actual types supported.
      reduce_op: Reduction method to use to reduce outputs from multiple
        replicas. Required if `set_last_step_output` is called in a replica
        context. Optional in cross_replica_context.
        When present, the outputs from all the replicas are reduced using the
        current distribution strategy's `reduce` method. Hence, the type of
        `output` must be what's supported by the corresponding `reduce` method.
        For e.g. if using MirroredStrategy and reduction is set, output
        must be a `PerReplica` value.
        The reduce method is also recorded in a dictionary
        `_last_step_outputs_reduce_ops` for later interpreting of the
        outputs as already reduced or not.
    """
    ...
  
  @property
  def non_tensor_outputs(self): # -> dict[Any, Any]:
    """A dictionary consisting of any non tensor outputs to be captured."""
    ...
  
  def set_non_tensor_output(self, name, output): # -> None:
    """Set `output` with `name` to be captured as a non tensor output."""
    ...
  


