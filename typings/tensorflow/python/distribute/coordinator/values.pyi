"""
This type stub file was generated by pyright.
"""

from tensorflow.python.data.ops import dataset_ops
from tensorflow.python.distribute.coordinator import remote_value
from tensorflow.python.framework import composite_tensor, type_spec as type_spec_lib
from tensorflow.python.util.tf_export import tf_export

"""Important value classes relevant to `ClusterCoordinator`.

This is currently under development and the API is subject to change.
"""
class RemoteValueImpl(remote_value.RemoteValue):
  """Implementation of `RemoteValue`."""
  def __init__(self, closure, type_spec) -> None:
    """Initializes a `RemoteValueImpl`.

    Args:
      closure: The closure from which the `RemoteValue` is created.
      type_spec: The type spec for this `RemoteValue` which is used to trace
        functions that take this `RemoteValue` as input.
    """
    ...
  
  def fetch(self): # -> defaultdict[Any, Any] | Any | list[Any] | object | None:
    ...
  
  def get(self): # -> defaultdict[Any, Any] | Any | list[Any] | object | None:
    ...
  


class RemoteVariable(RemoteValueImpl):
  """A RemoteValue that represents a mutable per-worker variable."""
  def get(self): # -> defaultdict[Any, Any] | Any | list[Any] | object | None:
    """Retrieve value with no caching to ensure we get the up-to-date value."""
    ...
  


@tf_export("distribute.experimental.coordinator.PerWorkerValues", "distribute.coordinator.PerWorkerValue", v1=[])
class PerWorkerValues(composite_tensor.CompositeTensor):
  """A container that holds a list of values, one value per worker.

  `tf.distribute.experimental.coordinator.PerWorkerValues` contains a collection
  of values, where each of the values is located on its corresponding worker,
  and upon being used as one of the `args` or `kwargs` of
  `tf.distribute.experimental.coordinator.ClusterCoordinator.schedule()`, the
  value specific to a worker will be passed into the function being executed at
  that corresponding worker.

  Currently, the only supported path to create an object of
  `tf.distribute.experimental.coordinator.PerWorkerValues` is through calling
  `iter` on a `ClusterCoordinator.create_per_worker_dataset`-returned
  distributed dataset instance. The mechanism to create a custom
  `tf.distribute.experimental.coordinator.PerWorkerValues` is not yet supported.
  """
  def __init__(self, values) -> None:
    ...
  


class PerWorkerValuesTypeSpec(type_spec_lib.TypeSpec):
  """TypeSpec for PerWorkerValues.

  It only support tracing a function using a PerWorkerValues.
  """
  def __init__(self, value_spec, descendant_type) -> None:
    ...
  
  @property
  def value_type(self): # -> Any:
    ...
  
  def most_specific_common_supertype(self, others):
    ...
  


class PerWorkerDatasetFromDatasetFunction:
  """Represents worker-distributed datasets created from dataset function."""
  def __init__(self, dataset_fn, coordinator) -> None:
    """Makes an iterable from datasets created by the given function.

    Args:
      dataset_fn: A function that returns a `Dataset`.
      coordinator: a `ClusterCoordinator` object, used to create dataset
        resources.
    """
    ...
  
  def build(self):
    """Trigger dataset creation on workers without creating an iterator.

    Returns:
      A PerWorkerValues object containing a tuple of RemoteValues, themselves
      containing the built Dataset for each worker
    """
    ...
  
  def __iter__(self): # -> PerWorkerDistributedIterator:
    ...
  
  @property
  def element_spec(self):
    """The type specification of an element of this dataset.

    This property is subject to change without notice.
    """
    ...
  


def serialize_dataset_to_graph(dataset): # -> Any:
  ...

class _RemoteDataset(dataset_ops.DatasetSource):
  """Creates a dataset given a graph def."""
  def __init__(self, graph_def, element_spec) -> None:
    ...
  
  @property
  def element_spec(self): # -> Any:
    ...
  


def deserialize_dataset_from_graph(graph_def, element_spec): # -> _RemoteDataset:
  ...

class PerWorkerDatasetFromDataset(PerWorkerDatasetFromDatasetFunction):
  """Represents worker-distributed datasets created from a dataset."""
  def __init__(self, dataset, coordinator) -> None:
    """Makes an iterable from datasets created by the given dataset.

    It creates a dataset_fn which deserializes a dataset from a graph under the
    hood.

    Args:
      dataset: A tf.data.Dataset, a DistributedDataset or a
        DistributedDatasetsFromFunction
      coordinator: a `ClusterCoordinator` object, used to create dataset
        resources.
    """
    ...
  


def get_per_worker_dataset(dataset_or_dataset_fn, coordinator): # -> PerWorkerDatasetFromDatasetFunction | PerWorkerDatasetFromDataset:
  """Returns a per-worker dataset from a dataset or a dataset function."""
  ...

class PerWorkerDistributedIterator(PerWorkerValues):
  """Distributed iterator for `ClusterCoordinator`."""
  def __next__(self):
    ...
  
  def get_next(self, name=...):
    """Returns the next input from the iterator for all replicas."""
    ...
  


