"""
This type stub file was generated by pyright.
"""

from tensorflow.security.fuzzing.py import annotation_types as _atypes
from tensorflow.python.util import dispatch as _dispatch
from tensorflow.python.util.tf_export import tf_export
from typing import Any, List, TypeVar
from typing_extensions import Annotated

"""Python wrappers around TensorFlow ops.

This file is MACHINE GENERATED! Do not edit.
"""
TV_AccumulatorApplyGradient_dtype = TypeVar("TV_AccumulatorApplyGradient_dtype", _atypes.BFloat16, _atypes.Complex128, _atypes.Complex64, _atypes.Float32, _atypes.Float64, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.UInt16, _atypes.UInt32, _atypes.UInt64, _atypes.UInt8)
def accumulator_apply_gradient(handle: Annotated[Any, _atypes.String], local_step: Annotated[Any, _atypes.Int64], gradient: Annotated[Any, TV_AccumulatorApplyGradient_dtype], name=...): # -> Operation:
  r"""Applies a gradient to a given accumulator.

  Does not add if local_step is lesser than the accumulator's global_step.

  Args:
    handle: A `Tensor` of type mutable `string`. The handle to a accumulator.
    local_step: A `Tensor` of type `int64`.
      The local_step value at which the gradient was computed.
    gradient: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `qint16`, `quint16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
      A tensor of the gradient to be accumulated.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

AccumulatorApplyGradient = ...
def accumulator_apply_gradient_eager_fallback(handle: Annotated[Any, _atypes.String], local_step: Annotated[Any, _atypes.Int64], gradient: Annotated[Any, TV_AccumulatorApplyGradient_dtype], name, ctx):
  ...

def accumulator_num_accumulated(handle: Annotated[Any, _atypes.String], name=...) -> Annotated[Any, _atypes.Int32]:
  r"""Returns the number of gradients aggregated in the given accumulators.

  Args:
    handle: A `Tensor` of type mutable `string`. The handle to an accumulator.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int32`.
  """
  ...

AccumulatorNumAccumulated = ...
def accumulator_num_accumulated_eager_fallback(handle: Annotated[Any, _atypes.String], name, ctx) -> Annotated[Any, _atypes.Int32]:
  ...

def accumulator_set_global_step(handle: Annotated[Any, _atypes.String], new_global_step: Annotated[Any, _atypes.Int64], name=...): # -> Operation:
  r"""Updates the accumulator with a new value for global_step.

  Logs warning if the accumulator's value is already higher than
  new_global_step.

  Args:
    handle: A `Tensor` of type mutable `string`. The handle to an accumulator.
    new_global_step: A `Tensor` of type `int64`.
      The new global_step value to set.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

AccumulatorSetGlobalStep = ...
def accumulator_set_global_step_eager_fallback(handle: Annotated[Any, _atypes.String], new_global_step: Annotated[Any, _atypes.Int64], name, ctx):
  ...

TV_AccumulatorTakeGradient_dtype = TypeVar("TV_AccumulatorTakeGradient_dtype", _atypes.BFloat16, _atypes.Complex128, _atypes.Complex64, _atypes.Float32, _atypes.Float64, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.UInt16, _atypes.UInt32, _atypes.UInt64, _atypes.UInt8)
def accumulator_take_gradient(handle: Annotated[Any, _atypes.String], num_required: Annotated[Any, _atypes.Int32], dtype: TV_AccumulatorTakeGradient_dtype, name=...) -> Annotated[Any, TV_AccumulatorTakeGradient_dtype]:
  r"""Extracts the average gradient in the given ConditionalAccumulator.

  The op blocks until sufficient (i.e., more than num_required)
  gradients have been accumulated.  If the accumulator has already
  aggregated more than num_required gradients, it returns the average of
  the accumulated gradients.  Also automatically increments the recorded
  global_step in the accumulator by 1, and resets the aggregate to 0.

  Args:
    handle: A `Tensor` of type mutable `string`. The handle to an accumulator.
    num_required: A `Tensor` of type `int32`.
      Number of gradients required before we return an aggregate.
    dtype: A `tf.DType` from: `tf.float32, tf.float64, tf.int32, tf.uint8, tf.int16, tf.int8, tf.complex64, tf.int64, tf.qint8, tf.quint8, tf.qint32, tf.bfloat16, tf.qint16, tf.quint16, tf.uint16, tf.complex128, tf.half, tf.uint32, tf.uint64`.
      The data type of accumulated gradients. Needs to correspond to the type
      of the accumulator.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `dtype`.
  """
  ...

AccumulatorTakeGradient = ...
def accumulator_take_gradient_eager_fallback(handle: Annotated[Any, _atypes.String], num_required: Annotated[Any, _atypes.Int32], dtype: TV_AccumulatorTakeGradient_dtype, name, ctx) -> Annotated[Any, TV_AccumulatorTakeGradient_dtype]:
  ...

def barrier(component_types, shapes=..., capacity: int = ..., container: str = ..., shared_name: str = ..., name=...) -> Annotated[Any, _atypes.String]:
  r"""Defines a barrier that persists across different graph executions.

  A barrier represents a key-value map, where each key is a string, and
  each value is a tuple of tensors.

  At runtime, the barrier contains 'complete' and 'incomplete'
  elements. A complete element has defined tensors for all components of
  its value tuple, and may be accessed using BarrierTakeMany. An
  incomplete element has some undefined components in its value tuple,
  and may be updated using BarrierInsertMany.

  Args:
    component_types: A list of `tf.DTypes` that has length `>= 1`.
      The type of each component in a value.
    shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
      The shape of each component in a value. Each shape must be 1 in the
      first dimension. The length of this attr must be the same as the length of
      component_types.
    capacity: An optional `int`. Defaults to `-1`.
      The capacity of the barrier.  The default capacity is MAX_INT32,
      which is the largest capacity of the underlying queue.
    container: An optional `string`. Defaults to `""`.
      If non-empty, this barrier is placed in the given container.
      Otherwise, a default container is used.
    shared_name: An optional `string`. Defaults to `""`.
      If non-empty, this barrier will be shared under the given name
      across multiple sessions.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type mutable `string`.
  """
  ...

Barrier = ...
def barrier_eager_fallback(component_types, shapes, capacity: int, container: str, shared_name: str, name, ctx) -> Annotated[Any, _atypes.String]:
  ...

def barrier_close(handle: Annotated[Any, _atypes.String], cancel_pending_enqueues: bool = ..., name=...): # -> Operation:
  r"""Closes the given barrier.

  This operation signals that no more new elements will be inserted in the
  given barrier. Subsequent InsertMany that try to introduce a new key will fail.
  Subsequent InsertMany operations that just add missing components to already
  existing elements will continue to succeed. Subsequent TakeMany operations will
  continue to succeed if sufficient completed elements remain in the barrier.
  Subsequent TakeMany operations that would block will fail immediately.

  Args:
    handle: A `Tensor` of type mutable `string`. The handle to a barrier.
    cancel_pending_enqueues: An optional `bool`. Defaults to `False`.
      If true, all pending enqueue requests that are
      blocked on the barrier's queue will be canceled. InsertMany will fail, even
      if no new key is introduced.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

BarrierClose = ...
def barrier_close_eager_fallback(handle: Annotated[Any, _atypes.String], cancel_pending_enqueues: bool, name, ctx):
  ...

def barrier_incomplete_size(handle: Annotated[Any, _atypes.String], name=...) -> Annotated[Any, _atypes.Int32]:
  r"""Computes the number of incomplete elements in the given barrier.

  Args:
    handle: A `Tensor` of type mutable `string`. The handle to a barrier.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int32`.
  """
  ...

BarrierIncompleteSize = ...
def barrier_incomplete_size_eager_fallback(handle: Annotated[Any, _atypes.String], name, ctx) -> Annotated[Any, _atypes.Int32]:
  ...

TV_BarrierInsertMany_T = TypeVar("TV_BarrierInsertMany_T", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def barrier_insert_many(handle: Annotated[Any, _atypes.String], keys: Annotated[Any, _atypes.String], values: Annotated[Any, TV_BarrierInsertMany_T], component_index: int, name=...): # -> Operation:
  r"""For each key, assigns the respective value to the specified component.

  If a key is not found in the barrier, this operation will create a new
  incomplete element. If a key is found in the barrier, and the element
  already has a value at component_index, this operation will fail with
  INVALID_ARGUMENT, and leave the barrier in an undefined state.

  Args:
    handle: A `Tensor` of type mutable `string`. The handle to a barrier.
    keys: A `Tensor` of type `string`.
      A one-dimensional tensor of keys, with length n.
    values: A `Tensor`.
      An any-dimensional tensor of values, which are associated with the
      respective keys. The 0th dimension must have length n.
    component_index: An `int`.
      The component of the barrier elements that is being assigned.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

BarrierInsertMany = ...
def barrier_insert_many_eager_fallback(handle: Annotated[Any, _atypes.String], keys: Annotated[Any, _atypes.String], values: Annotated[Any, TV_BarrierInsertMany_T], component_index: int, name, ctx):
  ...

def barrier_ready_size(handle: Annotated[Any, _atypes.String], name=...) -> Annotated[Any, _atypes.Int32]:
  r"""Computes the number of complete elements in the given barrier.

  Args:
    handle: A `Tensor` of type mutable `string`. The handle to a barrier.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int32`.
  """
  ...

BarrierReadySize = ...
def barrier_ready_size_eager_fallback(handle: Annotated[Any, _atypes.String], name, ctx) -> Annotated[Any, _atypes.Int32]:
  ...

_BarrierTakeManyOutput = ...
def barrier_take_many(handle: Annotated[Any, _atypes.String], num_elements: Annotated[Any, _atypes.Int32], component_types, allow_small_batch: bool = ..., wait_for_incomplete: bool = ..., timeout_ms: int = ..., name=...): # -> BarrierTakeMany:
  r"""Takes the given number of completed elements from a barrier.

  This operation concatenates completed-element component tensors along
  the 0th dimension to make a single component tensor.

  Elements come out of the barrier when they are complete, and in the order
  in which they were placed into the barrier.  The indices output provides
  information about the batch in which each element was originally inserted
  into the barrier.

  Args:
    handle: A `Tensor` of type mutable `string`. The handle to a barrier.
    num_elements: A `Tensor` of type `int32`.
      A single-element tensor containing the number of elements to
      take.
    component_types: A list of `tf.DTypes` that has length `>= 1`.
      The type of each component in a value.
    allow_small_batch: An optional `bool`. Defaults to `False`.
      Allow to return less than num_elements items if barrier is
      already closed.
    wait_for_incomplete: An optional `bool`. Defaults to `False`.
    timeout_ms: An optional `int`. Defaults to `-1`.
      If the queue is empty, this operation will block for up to
      timeout_ms milliseconds.
      Note: This option is not supported yet.
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (indices, keys, values).

    indices: A `Tensor` of type `int64`.
    keys: A `Tensor` of type `string`.
    values: A list of `Tensor` objects of type `component_types`.
  """
  ...

BarrierTakeMany = ...
def barrier_take_many_eager_fallback(handle: Annotated[Any, _atypes.String], num_elements: Annotated[Any, _atypes.Int32], component_types, allow_small_batch: bool, wait_for_incomplete: bool, timeout_ms: int, name, ctx):
  ...

TV_ConditionalAccumulator_dtype = TypeVar("TV_ConditionalAccumulator_dtype", _atypes.BFloat16, _atypes.Complex128, _atypes.Complex64, _atypes.Float32, _atypes.Float64, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.UInt16, _atypes.UInt32, _atypes.UInt64, _atypes.UInt8)
def conditional_accumulator(dtype: TV_ConditionalAccumulator_dtype, shape, container: str = ..., shared_name: str = ..., reduction_type: str = ..., name=...) -> Annotated[Any, _atypes.String]:
  r"""A conditional accumulator for aggregating gradients.

  The accumulator accepts gradients marked with local_step greater or
  equal to the most recent global_step known to the accumulator. The
  average can be extracted from the accumulator, provided sufficient
  gradients have been accumulated. Extracting the average automatically
  resets the aggregate to 0, and increments the global_step recorded by
  the accumulator.

  Args:
    dtype: A `tf.DType` from: `tf.float32, tf.float64, tf.int32, tf.uint8, tf.int16, tf.int8, tf.complex64, tf.int64, tf.qint8, tf.quint8, tf.qint32, tf.bfloat16, tf.qint16, tf.quint16, tf.uint16, tf.complex128, tf.half, tf.uint32, tf.uint64`.
      The type of the value being accumulated.
    shape: A `tf.TensorShape` or list of `ints`.
      The shape of the values, can be [], in which case shape is unknown.
    container: An optional `string`. Defaults to `""`.
      If non-empty, this accumulator is placed in the given container.
      Otherwise, a default container is used.
    shared_name: An optional `string`. Defaults to `""`.
      If non-empty, this accumulator will be shared under the
      given name across multiple sessions.
    reduction_type: An optional `string` from: `"MEAN", "SUM"`. Defaults to `"MEAN"`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type mutable `string`.
  """
  ...

ConditionalAccumulator = ...
def conditional_accumulator_eager_fallback(dtype: TV_ConditionalAccumulator_dtype, shape, container: str, shared_name: str, reduction_type: str, name, ctx) -> Annotated[Any, _atypes.String]:
  ...

def delete_session_tensor(handle: Annotated[Any, _atypes.String], name=...): # -> object | Operation | None:
  r"""Delete the tensor specified by its handle in the session.

  Args:
    handle: A `Tensor` of type `string`.
      The handle for a tensor stored in the session state.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

DeleteSessionTensor = ...
def delete_session_tensor_eager_fallback(handle: Annotated[Any, _atypes.String], name, ctx): # -> None:
  ...

TV_DynamicPartition_T = TypeVar("TV_DynamicPartition_T", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
@_dispatch.add_fallback_dispatch_list
@_dispatch.add_type_based_api_dispatcher
@tf_export('dynamic_partition')
def dynamic_partition(data: Annotated[Any, TV_DynamicPartition_T], partitions: Annotated[Any, _atypes.Int32], num_partitions: int, name=...): # -> object | _dispatcher_for_dynamic_partition | tuple[Any, ...] | list[Any]:
  r"""Partitions `data` into `num_partitions` tensors using indices from `partitions`.

  For each index tuple `js` of size `partitions.ndim`, the slice `data[js, ...]`
  becomes part of `outputs[partitions[js]]`.  The slices with `partitions[js] = i`
  are placed in `outputs[i]` in lexicographic order of `js`, and the first
  dimension of `outputs[i]` is the number of entries in `partitions` equal to `i`.
  In detail,

  ```python
      outputs[i].shape = [sum(partitions == i)] + data.shape[partitions.ndim:]

      outputs[i] = pack([data[js, ...] for js if partitions[js] == i])
  ```

  `data.shape` must start with `partitions.shape`.

  For example:

  ```python
      # Scalar partitions.
      partitions = 1
      num_partitions = 2
      data = [10, 20]
      outputs[0] = []  # Empty with shape [0, 2]
      outputs[1] = [[10, 20]]

      # Vector partitions.
      partitions = [0, 0, 1, 1, 0]
      num_partitions = 2
      data = [10, 20, 30, 40, 50]
      outputs[0] = [10, 20, 50]
      outputs[1] = [30, 40]
  ```

  See `dynamic_stitch` for an example on how to merge partitions back.

  <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
  <img style="width:100%" src="https://www.tensorflow.org/images/DynamicPartition.png" alt>
  </div>


  Raises:
    * `InvalidArgumentError` in following cases:
      - If partitions is not in range `[0, num_partiions)`
      - If `partitions.shape` does not match prefix of `data.shape` argument.

  Args:
    data: A `Tensor`.
    partitions: A `Tensor` of type `int32`.
      Any shape.  Indices in the range `[0, num_partitions)`.
    num_partitions: An `int` that is `>= 1`.
      The number of partitions to output.
    name: A name for the operation (optional).

  Returns:
    A list of `num_partitions` `Tensor` objects with the same type as `data`.
  """
  ...

DynamicPartition = ...
_dispatcher_for_dynamic_partition = dynamic_partition._tf_type_based_dispatcher.Dispatch
def dynamic_partition_eager_fallback(data: Annotated[Any, TV_DynamicPartition_T], partitions: Annotated[Any, _atypes.Int32], num_partitions: int, name, ctx): # -> object:
  ...

TV_DynamicStitch_T = TypeVar("TV_DynamicStitch_T", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
@_dispatch.add_fallback_dispatch_list
@_dispatch.add_type_based_api_dispatcher
@tf_export('dynamic_stitch')
def dynamic_stitch(indices: Annotated[List[Any], _atypes.Int32], data: Annotated[List[Any], TV_DynamicStitch_T], name=...) -> Annotated[Any, TV_DynamicStitch_T]:
  r"""Interleave the values from the `data` tensors into a single tensor.

  Builds a merged tensor such that

  ```python
      merged[indices[m][i, ..., j], ...] = data[m][i, ..., j, ...]
  ```

  For example, if each `indices[m]` is scalar or vector, we have

  ```python
      # Scalar indices:
      merged[indices[m], ...] = data[m][...]

      # Vector indices:
      merged[indices[m][i], ...] = data[m][i, ...]
  ```

  Each `data[i].shape` must start with the corresponding `indices[i].shape`,
  and the rest of `data[i].shape` must be constant w.r.t. `i`.  That is, we
  must have `data[i].shape = indices[i].shape + constant`.  In terms of this
  `constant`, the output shape is

      merged.shape = [max(indices) + 1] + constant

  Values are merged in order, so if an index appears in both `indices[m][i]` and
  `indices[n][j]` for `(m,i) < (n,j)` the slice `data[n][j]` will appear in the
  merged result. If you do not need this guarantee, ParallelDynamicStitch might
  perform better on some devices.

  For example:

  ```python
      indices[0] = 6
      indices[1] = [4, 1]
      indices[2] = [[5, 2], [0, 3]]
      data[0] = [61, 62]
      data[1] = [[41, 42], [11, 12]]
      data[2] = [[[51, 52], [21, 22]], [[1, 2], [31, 32]]]
      merged = [[1, 2], [11, 12], [21, 22], [31, 32], [41, 42],
                [51, 52], [61, 62]]
  ```

  This method can be used to merge partitions created by `dynamic_partition`
  as illustrated on the following example:

  ```python
      # Apply function (increments x_i) on elements for which a certain condition
      # apply (x_i != -1 in this example).
      x=tf.constant([0.1, -1., 5.2, 4.3, -1., 7.4])
      condition_mask=tf.not_equal(x,tf.constant(-1.))
      partitioned_data = tf.dynamic_partition(
          x, tf.cast(condition_mask, tf.int32) , 2)
      partitioned_data[1] = partitioned_data[1] + 1.0
      condition_indices = tf.dynamic_partition(
          tf.range(tf.shape(x)[0]), tf.cast(condition_mask, tf.int32) , 2)
      x = tf.dynamic_stitch(condition_indices, partitioned_data)
      # Here x=[1.1, -1., 6.2, 5.3, -1, 8.4], the -1. values remain
      # unchanged.
  ```

  <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
  <img style="width:100%" src="https://www.tensorflow.org/images/DynamicStitch.png" alt>
  </div>

  Args:
    indices: A list of at least 1 `Tensor` objects with type `int32`.
    data: A list with the same length as `indices` of `Tensor` objects with the same type.
    name: A name for the operation (optional).

  Returns:
    A `Tensor`. Has the same type as `data`.
  """
  ...

DynamicStitch = ...
_dispatcher_for_dynamic_stitch = dynamic_stitch._tf_type_based_dispatcher.Dispatch
def dynamic_stitch_eager_fallback(indices: Annotated[List[Any], _atypes.Int32], data: Annotated[List[Any], TV_DynamicStitch_T], name, ctx) -> Annotated[Any, TV_DynamicStitch_T]:
  ...

def fifo_queue(component_types, shapes=..., capacity: int = ..., container: str = ..., shared_name: str = ..., name=...) -> Annotated[Any, _atypes.String]:
  r"""A queue that produces elements in first-in first-out order.

  Args:
    component_types: A list of `tf.DTypes` that has length `>= 1`.
      The type of each component in a value.
    shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
      The shape of each component in a value. The length of this attr must
      be either 0 or the same as the length of component_types. If the length of
      this attr is 0, the shapes of queue elements are not constrained, and
      only one element may be dequeued at a time.
    capacity: An optional `int`. Defaults to `-1`.
      The upper bound on the number of elements in this queue.
      Negative numbers mean no limit.
    container: An optional `string`. Defaults to `""`.
      If non-empty, this queue is placed in the given container.
      Otherwise, a default container is used.
    shared_name: An optional `string`. Defaults to `""`.
      If non-empty, this queue will be shared under the given name
      across multiple sessions.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type mutable `string`.
  """
  ...

FIFOQueue = ...
def fifo_queue_eager_fallback(component_types, shapes, capacity: int, container: str, shared_name: str, name, ctx) -> Annotated[Any, _atypes.String]:
  ...

def fifo_queue_v2(component_types, shapes=..., capacity: int = ..., container: str = ..., shared_name: str = ..., name=...) -> Annotated[Any, _atypes.Resource]:
  r"""A queue that produces elements in first-in first-out order.

  Args:
    component_types: A list of `tf.DTypes` that has length `>= 1`.
      The type of each component in a value.
    shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
      The shape of each component in a value. The length of this attr must
      be either 0 or the same as the length of component_types. If the length of
      this attr is 0, the shapes of queue elements are not constrained, and
      only one element may be dequeued at a time.
    capacity: An optional `int`. Defaults to `-1`.
      The upper bound on the number of elements in this queue.
      Negative numbers mean no limit.
    container: An optional `string`. Defaults to `""`.
      If non-empty, this queue is placed in the given container.
      Otherwise, a default container is used.
    shared_name: An optional `string`. Defaults to `""`.
      If non-empty, this queue will be shared under the given name
      across multiple sessions.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `resource`.
  """
  ...

FIFOQueueV2 = ...
def fifo_queue_v2_eager_fallback(component_types, shapes, capacity: int, container: str, shared_name: str, name, ctx) -> Annotated[Any, _atypes.Resource]:
  ...

def fake_queue(resource: Annotated[Any, _atypes.Resource], name=...) -> Annotated[Any, _atypes.String]:
  r"""Deprecated. Do not use.

  Args:
    resource: A `Tensor` of type `resource`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type mutable `string`.
  """
  ...

FakeQueue = ...
def fake_queue_eager_fallback(resource: Annotated[Any, _atypes.Resource], name, ctx) -> Annotated[Any, _atypes.String]:
  ...

TV_GetSessionHandle_T = TypeVar("TV_GetSessionHandle_T", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def get_session_handle(value: Annotated[Any, TV_GetSessionHandle_T], name=...) -> Annotated[Any, _atypes.String]:
  r"""Store the input tensor in the state of the current session.

  Args:
    value: A `Tensor`. The tensor to be stored.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `string`.
  """
  ...

GetSessionHandle = ...
def get_session_handle_eager_fallback(value: Annotated[Any, TV_GetSessionHandle_T], name, ctx) -> Annotated[Any, _atypes.String]:
  ...

TV_GetSessionHandleV2_T = TypeVar("TV_GetSessionHandleV2_T", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def get_session_handle_v2(value: Annotated[Any, TV_GetSessionHandleV2_T], name=...) -> Annotated[Any, _atypes.Resource]:
  r"""Store the input tensor in the state of the current session.

  Args:
    value: A `Tensor`. The tensor to be stored.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `resource`.
  """
  ...

GetSessionHandleV2 = ...
def get_session_handle_v2_eager_fallback(value: Annotated[Any, TV_GetSessionHandleV2_T], name, ctx) -> Annotated[Any, _atypes.Resource]:
  ...

TV_GetSessionTensor_dtype = TypeVar("TV_GetSessionTensor_dtype", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def get_session_tensor(handle: Annotated[Any, _atypes.String], dtype: TV_GetSessionTensor_dtype, name=...) -> Annotated[Any, TV_GetSessionTensor_dtype]:
  r"""Get the value of the tensor specified by its handle.

  Args:
    handle: A `Tensor` of type `string`.
      The handle for a tensor stored in the session state.
    dtype: A `tf.DType`. The type of the output value.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `dtype`.
  """
  ...

GetSessionTensor = ...
def get_session_tensor_eager_fallback(handle: Annotated[Any, _atypes.String], dtype: TV_GetSessionTensor_dtype, name, ctx) -> Annotated[Any, TV_GetSessionTensor_dtype]:
  ...

def map_clear(dtypes, capacity: int = ..., memory_limit: int = ..., container: str = ..., shared_name: str = ..., name=...): # -> object | Operation | None:
  r"""Op removes all elements in the underlying container.

  Args:
    dtypes: A list of `tf.DTypes`.
    capacity: An optional `int` that is `>= 0`. Defaults to `0`.
    memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
    container: An optional `string`. Defaults to `""`.
    shared_name: An optional `string`. Defaults to `""`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

MapClear = ...
def map_clear_eager_fallback(dtypes, capacity: int, memory_limit: int, container: str, shared_name: str, name, ctx): # -> None:
  ...

def map_incomplete_size(dtypes, capacity: int = ..., memory_limit: int = ..., container: str = ..., shared_name: str = ..., name=...) -> Annotated[Any, _atypes.Int32]:
  r"""Op returns the number of incomplete elements in the underlying container.

  Args:
    dtypes: A list of `tf.DTypes`.
    capacity: An optional `int` that is `>= 0`. Defaults to `0`.
    memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
    container: An optional `string`. Defaults to `""`.
    shared_name: An optional `string`. Defaults to `""`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int32`.
  """
  ...

MapIncompleteSize = ...
def map_incomplete_size_eager_fallback(dtypes, capacity: int, memory_limit: int, container: str, shared_name: str, name, ctx) -> Annotated[Any, _atypes.Int32]:
  ...

def map_peek(key: Annotated[Any, _atypes.Int64], indices: Annotated[Any, _atypes.Int32], dtypes, capacity: int = ..., memory_limit: int = ..., container: str = ..., shared_name: str = ..., name=...): # -> object | Operation | tuple[Any, ...] | list[Any]:
  r"""Op peeks at the values at the specified key.  If the

  underlying container does not contain this key
  this op will block until it does.

  Args:
    key: A `Tensor` of type `int64`.
    indices: A `Tensor` of type `int32`.
    dtypes: A list of `tf.DTypes` that has length `>= 1`.
    capacity: An optional `int` that is `>= 0`. Defaults to `0`.
    memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
    container: An optional `string`. Defaults to `""`.
    shared_name: An optional `string`. Defaults to `""`.
    name: A name for the operation (optional).

  Returns:
    A list of `Tensor` objects of type `dtypes`.
  """
  ...

MapPeek = ...
def map_peek_eager_fallback(key: Annotated[Any, _atypes.Int64], indices: Annotated[Any, _atypes.Int32], dtypes, capacity: int, memory_limit: int, container: str, shared_name: str, name, ctx): # -> object:
  ...

def map_size(dtypes, capacity: int = ..., memory_limit: int = ..., container: str = ..., shared_name: str = ..., name=...) -> Annotated[Any, _atypes.Int32]:
  r"""Op returns the number of elements in the underlying container.

  Args:
    dtypes: A list of `tf.DTypes`.
    capacity: An optional `int` that is `>= 0`. Defaults to `0`.
    memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
    container: An optional `string`. Defaults to `""`.
    shared_name: An optional `string`. Defaults to `""`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int32`.
  """
  ...

MapSize = ...
def map_size_eager_fallback(dtypes, capacity: int, memory_limit: int, container: str, shared_name: str, name, ctx) -> Annotated[Any, _atypes.Int32]:
  ...

def map_stage(key: Annotated[Any, _atypes.Int64], indices: Annotated[Any, _atypes.Int32], values, dtypes, capacity: int = ..., memory_limit: int = ..., container: str = ..., shared_name: str = ..., name=...): # -> object | Operation | None:
  r"""Stage (key, values) in the underlying container which behaves like a hashtable.

  Args:
    key: A `Tensor` of type `int64`. int64
    indices: A `Tensor` of type `int32`.
    values: A list of `Tensor` objects. a list of tensors
      dtypes A list of data types that inserted values should adhere to.
    dtypes: A list of `tf.DTypes`.
    capacity: An optional `int` that is `>= 0`. Defaults to `0`.
      Maximum number of elements in the Staging Area. If > 0, inserts
      on the container will block when the capacity is reached.
    memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
    container: An optional `string`. Defaults to `""`.
      If non-empty, this queue is placed in the given container. Otherwise,
      a default container is used.
    shared_name: An optional `string`. Defaults to `""`.
      It is necessary to match this name to the matching Unstage Op.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

MapStage = ...
def map_stage_eager_fallback(key: Annotated[Any, _atypes.Int64], indices: Annotated[Any, _atypes.Int32], values, dtypes, capacity: int, memory_limit: int, container: str, shared_name: str, name, ctx): # -> None:
  ...

def map_unstage(key: Annotated[Any, _atypes.Int64], indices: Annotated[Any, _atypes.Int32], dtypes, capacity: int = ..., memory_limit: int = ..., container: str = ..., shared_name: str = ..., name=...): # -> object | Operation | tuple[Any, ...] | list[Any]:
  r"""Op removes and returns the values associated with the key

  from the underlying container.   If the underlying container
  does not contain this key, the op will block until it does.

  Args:
    key: A `Tensor` of type `int64`.
    indices: A `Tensor` of type `int32`.
    dtypes: A list of `tf.DTypes` that has length `>= 1`.
    capacity: An optional `int` that is `>= 0`. Defaults to `0`.
    memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
    container: An optional `string`. Defaults to `""`.
    shared_name: An optional `string`. Defaults to `""`.
    name: A name for the operation (optional).

  Returns:
    A list of `Tensor` objects of type `dtypes`.
  """
  ...

MapUnstage = ...
def map_unstage_eager_fallback(key: Annotated[Any, _atypes.Int64], indices: Annotated[Any, _atypes.Int32], dtypes, capacity: int, memory_limit: int, container: str, shared_name: str, name, ctx): # -> object:
  ...

_MapUnstageNoKeyOutput = ...
def map_unstage_no_key(indices: Annotated[Any, _atypes.Int32], dtypes, capacity: int = ..., memory_limit: int = ..., container: str = ..., shared_name: str = ..., name=...): # -> MapUnstageNoKey:
  r"""Op removes and returns a random (key, value)

  from the underlying container.   If the underlying container
  does not contain elements, the op will block until it does.

  Args:
    indices: A `Tensor` of type `int32`.
    dtypes: A list of `tf.DTypes` that has length `>= 1`.
    capacity: An optional `int` that is `>= 0`. Defaults to `0`.
    memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
    container: An optional `string`. Defaults to `""`.
    shared_name: An optional `string`. Defaults to `""`.
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (key, values).

    key: A `Tensor` of type `int64`.
    values: A list of `Tensor` objects of type `dtypes`.
  """
  ...

MapUnstageNoKey = ...
def map_unstage_no_key_eager_fallback(indices: Annotated[Any, _atypes.Int32], dtypes, capacity: int, memory_limit: int, container: str, shared_name: str, name, ctx): # -> MapUnstageNoKey:
  ...

def ordered_map_clear(dtypes, capacity: int = ..., memory_limit: int = ..., container: str = ..., shared_name: str = ..., name=...): # -> object | Operation | None:
  r"""Op removes all elements in the underlying container.

  Args:
    dtypes: A list of `tf.DTypes`.
    capacity: An optional `int` that is `>= 0`. Defaults to `0`.
    memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
    container: An optional `string`. Defaults to `""`.
    shared_name: An optional `string`. Defaults to `""`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

OrderedMapClear = ...
def ordered_map_clear_eager_fallback(dtypes, capacity: int, memory_limit: int, container: str, shared_name: str, name, ctx): # -> None:
  ...

def ordered_map_incomplete_size(dtypes, capacity: int = ..., memory_limit: int = ..., container: str = ..., shared_name: str = ..., name=...) -> Annotated[Any, _atypes.Int32]:
  r"""Op returns the number of incomplete elements in the underlying container.

  Args:
    dtypes: A list of `tf.DTypes`.
    capacity: An optional `int` that is `>= 0`. Defaults to `0`.
    memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
    container: An optional `string`. Defaults to `""`.
    shared_name: An optional `string`. Defaults to `""`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int32`.
  """
  ...

OrderedMapIncompleteSize = ...
def ordered_map_incomplete_size_eager_fallback(dtypes, capacity: int, memory_limit: int, container: str, shared_name: str, name, ctx) -> Annotated[Any, _atypes.Int32]:
  ...

def ordered_map_peek(key: Annotated[Any, _atypes.Int64], indices: Annotated[Any, _atypes.Int32], dtypes, capacity: int = ..., memory_limit: int = ..., container: str = ..., shared_name: str = ..., name=...): # -> object | Operation | tuple[Any, ...] | list[Any]:
  r"""Op peeks at the values at the specified key.  If the

  underlying container does not contain this key
  this op will block until it does.   This Op is optimized for
  performance.

  Args:
    key: A `Tensor` of type `int64`.
    indices: A `Tensor` of type `int32`.
    dtypes: A list of `tf.DTypes` that has length `>= 1`.
    capacity: An optional `int` that is `>= 0`. Defaults to `0`.
    memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
    container: An optional `string`. Defaults to `""`.
    shared_name: An optional `string`. Defaults to `""`.
    name: A name for the operation (optional).

  Returns:
    A list of `Tensor` objects of type `dtypes`.
  """
  ...

OrderedMapPeek = ...
def ordered_map_peek_eager_fallback(key: Annotated[Any, _atypes.Int64], indices: Annotated[Any, _atypes.Int32], dtypes, capacity: int, memory_limit: int, container: str, shared_name: str, name, ctx): # -> object:
  ...

def ordered_map_size(dtypes, capacity: int = ..., memory_limit: int = ..., container: str = ..., shared_name: str = ..., name=...) -> Annotated[Any, _atypes.Int32]:
  r"""Op returns the number of elements in the underlying container.

  Args:
    dtypes: A list of `tf.DTypes`.
    capacity: An optional `int` that is `>= 0`. Defaults to `0`.
    memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
    container: An optional `string`. Defaults to `""`.
    shared_name: An optional `string`. Defaults to `""`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int32`.
  """
  ...

OrderedMapSize = ...
def ordered_map_size_eager_fallback(dtypes, capacity: int, memory_limit: int, container: str, shared_name: str, name, ctx) -> Annotated[Any, _atypes.Int32]:
  ...

def ordered_map_stage(key: Annotated[Any, _atypes.Int64], indices: Annotated[Any, _atypes.Int32], values, dtypes, capacity: int = ..., memory_limit: int = ..., container: str = ..., shared_name: str = ..., name=...): # -> object | Operation | None:
  r"""Stage (key, values) in the underlying container which behaves like a ordered

  associative container.   Elements are ordered by key.

  Args:
    key: A `Tensor` of type `int64`. int64
    indices: A `Tensor` of type `int32`.
    values: A list of `Tensor` objects. a list of tensors
      dtypes A list of data types that inserted values should adhere to.
    dtypes: A list of `tf.DTypes`.
    capacity: An optional `int` that is `>= 0`. Defaults to `0`.
      Maximum number of elements in the Staging Area. If > 0, inserts
      on the container will block when the capacity is reached.
    memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
    container: An optional `string`. Defaults to `""`.
      If non-empty, this queue is placed in the given container. Otherwise,
      a default container is used.
    shared_name: An optional `string`. Defaults to `""`.
      It is necessary to match this name to the matching Unstage Op.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

OrderedMapStage = ...
def ordered_map_stage_eager_fallback(key: Annotated[Any, _atypes.Int64], indices: Annotated[Any, _atypes.Int32], values, dtypes, capacity: int, memory_limit: int, container: str, shared_name: str, name, ctx): # -> None:
  ...

def ordered_map_unstage(key: Annotated[Any, _atypes.Int64], indices: Annotated[Any, _atypes.Int32], dtypes, capacity: int = ..., memory_limit: int = ..., container: str = ..., shared_name: str = ..., name=...): # -> object | Operation | tuple[Any, ...] | list[Any]:
  r"""Op removes and returns the values associated with the key

  from the underlying container.   If the underlying container
  does not contain this key, the op will block until it does.

  Args:
    key: A `Tensor` of type `int64`.
    indices: A `Tensor` of type `int32`.
    dtypes: A list of `tf.DTypes` that has length `>= 1`.
    capacity: An optional `int` that is `>= 0`. Defaults to `0`.
    memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
    container: An optional `string`. Defaults to `""`.
    shared_name: An optional `string`. Defaults to `""`.
    name: A name for the operation (optional).

  Returns:
    A list of `Tensor` objects of type `dtypes`.
  """
  ...

OrderedMapUnstage = ...
def ordered_map_unstage_eager_fallback(key: Annotated[Any, _atypes.Int64], indices: Annotated[Any, _atypes.Int32], dtypes, capacity: int, memory_limit: int, container: str, shared_name: str, name, ctx): # -> object:
  ...

_OrderedMapUnstageNoKeyOutput = ...
def ordered_map_unstage_no_key(indices: Annotated[Any, _atypes.Int32], dtypes, capacity: int = ..., memory_limit: int = ..., container: str = ..., shared_name: str = ..., name=...): # -> OrderedMapUnstageNoKey:
  r"""Op removes and returns the (key, value) element with the smallest

  key from the underlying container.   If the underlying container
  does not contain elements, the op will block until it does.

  Args:
    indices: A `Tensor` of type `int32`.
    dtypes: A list of `tf.DTypes` that has length `>= 1`.
    capacity: An optional `int` that is `>= 0`. Defaults to `0`.
    memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
    container: An optional `string`. Defaults to `""`.
    shared_name: An optional `string`. Defaults to `""`.
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (key, values).

    key: A `Tensor` of type `int64`.
    values: A list of `Tensor` objects of type `dtypes`.
  """
  ...

OrderedMapUnstageNoKey = ...
def ordered_map_unstage_no_key_eager_fallback(indices: Annotated[Any, _atypes.Int32], dtypes, capacity: int, memory_limit: int, container: str, shared_name: str, name, ctx): # -> OrderedMapUnstageNoKey:
  ...

def padding_fifo_queue(component_types, shapes=..., capacity: int = ..., container: str = ..., shared_name: str = ..., name=...) -> Annotated[Any, _atypes.String]:
  r"""A queue that produces elements in first-in first-out order.

  Variable-size shapes are allowed by setting the corresponding shape dimensions
  to 0 in the shape attr.  In this case DequeueMany will pad up to the maximum
  size of any given element in the minibatch.  See below for details.

  Args:
    component_types: A list of `tf.DTypes` that has length `>= 1`.
      The type of each component in a value.
    shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
      The shape of each component in a value. The length of this attr must
      be either 0 or the same as the length of component_types.
      Shapes of fixed rank but variable size are allowed by setting
      any shape dimension to -1.  In this case, the inputs' shape may vary along
      the given dimension, and DequeueMany will pad the given dimension with
      zeros up to the maximum shape of all elements in the given batch.
      If the length of this attr is 0, different queue elements may have
      different ranks and shapes, but only one element may be dequeued at a time.
    capacity: An optional `int`. Defaults to `-1`.
      The upper bound on the number of elements in this queue.
      Negative numbers mean no limit.
    container: An optional `string`. Defaults to `""`.
      If non-empty, this queue is placed in the given container.
      Otherwise, a default container is used.
    shared_name: An optional `string`. Defaults to `""`.
      If non-empty, this queue will be shared under the given name
      across multiple sessions.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type mutable `string`.
  """
  ...

PaddingFIFOQueue = ...
def padding_fifo_queue_eager_fallback(component_types, shapes, capacity: int, container: str, shared_name: str, name, ctx) -> Annotated[Any, _atypes.String]:
  ...

def padding_fifo_queue_v2(component_types, shapes=..., capacity: int = ..., container: str = ..., shared_name: str = ..., name=...) -> Annotated[Any, _atypes.Resource]:
  r"""A queue that produces elements in first-in first-out order.

  Variable-size shapes are allowed by setting the corresponding shape dimensions
  to 0 in the shape attr.  In this case DequeueMany will pad up to the maximum
  size of any given element in the minibatch.  See below for details.

  Args:
    component_types: A list of `tf.DTypes` that has length `>= 1`.
      The type of each component in a value.
    shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
      The shape of each component in a value. The length of this attr must
      be either 0 or the same as the length of component_types.
      Shapes of fixed rank but variable size are allowed by setting
      any shape dimension to -1.  In this case, the inputs' shape may vary along
      the given dimension, and DequeueMany will pad the given dimension with
      zeros up to the maximum shape of all elements in the given batch.
      If the length of this attr is 0, different queue elements may have
      different ranks and shapes, but only one element may be dequeued at a time.
    capacity: An optional `int`. Defaults to `-1`.
      The upper bound on the number of elements in this queue.
      Negative numbers mean no limit.
    container: An optional `string`. Defaults to `""`.
      If non-empty, this queue is placed in the given container.
      Otherwise, a default container is used.
    shared_name: An optional `string`. Defaults to `""`.
      If non-empty, this queue will be shared under the given name
      across multiple sessions.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `resource`.
  """
  ...

PaddingFIFOQueueV2 = ...
def padding_fifo_queue_v2_eager_fallback(component_types, shapes, capacity: int, container: str, shared_name: str, name, ctx) -> Annotated[Any, _atypes.Resource]:
  ...

TV_ParallelDynamicStitch_T = TypeVar("TV_ParallelDynamicStitch_T", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def parallel_dynamic_stitch(indices: Annotated[List[Any], _atypes.Int32], data: Annotated[List[Any], TV_ParallelDynamicStitch_T], name=...) -> Annotated[Any, TV_ParallelDynamicStitch_T]:
  r"""Interleave the values from the `data` tensors into a single tensor.

  Builds a merged tensor such that

  ```python
      merged[indices[m][i, ..., j], ...] = data[m][i, ..., j, ...]
  ```

  For example, if each `indices[m]` is scalar or vector, we have

  ```python
      # Scalar indices:
      merged[indices[m], ...] = data[m][...]

      # Vector indices:
      merged[indices[m][i], ...] = data[m][i, ...]
  ```

  Each `data[i].shape` must start with the corresponding `indices[i].shape`,
  and the rest of `data[i].shape` must be constant w.r.t. `i`.  That is, we
  must have `data[i].shape = indices[i].shape + constant`.  In terms of this
  `constant`, the output shape is

      merged.shape = [max(indices)] + constant

  Values may be merged in parallel, so if an index appears in both `indices[m][i]`
  and `indices[n][j]`, the result may be invalid. This differs from the normal
  DynamicStitch operator that defines the behavior in that case.

  For example:

  ```python
      indices[0] = 6
      indices[1] = [4, 1]
      indices[2] = [[5, 2], [0, 3]]
      data[0] = [61, 62]
      data[1] = [[41, 42], [11, 12]]
      data[2] = [[[51, 52], [21, 22]], [[1, 2], [31, 32]]]
      merged = [[1, 2], [11, 12], [21, 22], [31, 32], [41, 42],
                [51, 52], [61, 62]]
  ```

  This method can be used to merge partitions created by `dynamic_partition`
  as illustrated on the following example:

  ```python
      # Apply function (increments x_i) on elements for which a certain condition
      # apply (x_i != -1 in this example).
      x=tf.constant([0.1, -1., 5.2, 4.3, -1., 7.4])
      condition_mask=tf.not_equal(x,tf.constant(-1.))
      partitioned_data = tf.dynamic_partition(
          x, tf.cast(condition_mask, tf.int32) , 2)
      partitioned_data[1] = partitioned_data[1] + 1.0
      condition_indices = tf.dynamic_partition(
          tf.range(tf.shape(x)[0]), tf.cast(condition_mask, tf.int32) , 2)
      x = tf.dynamic_stitch(condition_indices, partitioned_data)
      # Here x=[1.1, -1., 6.2, 5.3, -1, 8.4], the -1. values remain
      # unchanged.
  ```

  <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
  <img style="width:100%" src="https://www.tensorflow.org/images/DynamicStitch.png" alt>
  </div>

  Args:
    indices: A list of at least 1 `Tensor` objects with type `int32`.
    data: A list with the same length as `indices` of `Tensor` objects with the same type.
    name: A name for the operation (optional).

  Returns:
    A `Tensor`. Has the same type as `data`.
  """
  ...

ParallelDynamicStitch = ...
def parallel_dynamic_stitch_eager_fallback(indices: Annotated[List[Any], _atypes.Int32], data: Annotated[List[Any], TV_ParallelDynamicStitch_T], name, ctx) -> Annotated[Any, TV_ParallelDynamicStitch_T]:
  ...

def priority_queue(shapes, component_types=..., capacity: int = ..., container: str = ..., shared_name: str = ..., name=...) -> Annotated[Any, _atypes.String]:
  r"""A queue that produces elements sorted by the first component value.

  Note that the PriorityQueue requires the first component of any element
  to be a scalar int64, in addition to the other elements declared by
  component_types.  Therefore calls to Enqueue and EnqueueMany (resp. Dequeue
  and DequeueMany) on a PriorityQueue will all require (resp. output) one extra
  entry in their input (resp. output) lists.

  Args:
    shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`).
      The shape of each component in a value. The length of this attr must
      be either 0 or the same as the length of component_types. If the length of
      this attr is 0, the shapes of queue elements are not constrained, and
      only one element may be dequeued at a time.
    component_types: An optional list of `tf.DTypes`. Defaults to `[]`.
      The type of each component in a value.
    capacity: An optional `int`. Defaults to `-1`.
      The upper bound on the number of elements in this queue.
      Negative numbers mean no limit.
    container: An optional `string`. Defaults to `""`.
      If non-empty, this queue is placed in the given container.
      Otherwise, a default container is used.
    shared_name: An optional `string`. Defaults to `""`.
      If non-empty, this queue will be shared under the given name
      across multiple sessions.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type mutable `string`.
  """
  ...

PriorityQueue = ...
def priority_queue_eager_fallback(shapes, component_types, capacity: int, container: str, shared_name: str, name, ctx) -> Annotated[Any, _atypes.String]:
  ...

def priority_queue_v2(shapes, component_types=..., capacity: int = ..., container: str = ..., shared_name: str = ..., name=...) -> Annotated[Any, _atypes.Resource]:
  r"""A queue that produces elements sorted by the first component value.

  Note that the PriorityQueue requires the first component of any element
  to be a scalar int64, in addition to the other elements declared by
  component_types.  Therefore calls to Enqueue and EnqueueMany (resp. Dequeue
  and DequeueMany) on a PriorityQueue will all require (resp. output) one extra
  entry in their input (resp. output) lists.

  Args:
    shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`).
      The shape of each component in a value. The length of this attr must
      be either 0 or the same as the length of component_types. If the length of
      this attr is 0, the shapes of queue elements are not constrained, and
      only one element may be dequeued at a time.
    component_types: An optional list of `tf.DTypes`. Defaults to `[]`.
      The type of each component in a value.
    capacity: An optional `int`. Defaults to `-1`.
      The upper bound on the number of elements in this queue.
      Negative numbers mean no limit.
    container: An optional `string`. Defaults to `""`.
      If non-empty, this queue is placed in the given container.
      Otherwise, a default container is used.
    shared_name: An optional `string`. Defaults to `""`.
      If non-empty, this queue will be shared under the given name
      across multiple sessions.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `resource`.
  """
  ...

PriorityQueueV2 = ...
def priority_queue_v2_eager_fallback(shapes, component_types, capacity: int, container: str, shared_name: str, name, ctx) -> Annotated[Any, _atypes.Resource]:
  ...

def queue_close(handle: Annotated[Any, _atypes.String], cancel_pending_enqueues: bool = ..., name=...): # -> Operation:
  r"""Closes the given queue.

  This operation signals that no more elements will be enqueued in the
  given queue. Subsequent Enqueue(Many) operations will fail.
  Subsequent Dequeue(Many) operations will continue to succeed if
  sufficient elements remain in the queue. Subsequent Dequeue(Many)
  operations that would block will fail immediately.

  Args:
    handle: A `Tensor` of type mutable `string`. The handle to a queue.
    cancel_pending_enqueues: An optional `bool`. Defaults to `False`.
      If true, all pending enqueue requests that are
      blocked on the given queue will be canceled.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

QueueClose = ...
def queue_close_eager_fallback(handle: Annotated[Any, _atypes.String], cancel_pending_enqueues: bool, name, ctx):
  ...

def queue_close_v2(handle: Annotated[Any, _atypes.Resource], cancel_pending_enqueues: bool = ..., name=...): # -> object | Operation | None:
  r"""Closes the given queue.

  This operation signals that no more elements will be enqueued in the
  given queue. Subsequent Enqueue(Many) operations will fail.
  Subsequent Dequeue(Many) operations will continue to succeed if
  sufficient elements remain in the queue. Subsequent Dequeue(Many)
  operations that would block will fail immediately.

  Args:
    handle: A `Tensor` of type `resource`. The handle to a queue.
    cancel_pending_enqueues: An optional `bool`. Defaults to `False`.
      If true, all pending enqueue requests that are
      blocked on the given queue will be canceled.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

QueueCloseV2 = ...
def queue_close_v2_eager_fallback(handle: Annotated[Any, _atypes.Resource], cancel_pending_enqueues: bool, name, ctx): # -> None:
  ...

def queue_dequeue(handle: Annotated[Any, _atypes.String], component_types, timeout_ms: int = ..., name=...): # -> tuple[Any, ...] | list[Any]:
  r"""Dequeues a tuple of one or more tensors from the given queue.

  This operation has k outputs, where k is the number of components
  in the tuples stored in the given queue, and output i is the ith
  component of the dequeued tuple.

  N.B. If the queue is empty, this operation will block until an element
  has been dequeued (or 'timeout_ms' elapses, if specified).

  Args:
    handle: A `Tensor` of type mutable `string`. The handle to a queue.
    component_types: A list of `tf.DTypes` that has length `>= 1`.
      The type of each component in a tuple.
    timeout_ms: An optional `int`. Defaults to `-1`.
      If the queue is empty, this operation will block for up to
      timeout_ms milliseconds.
      Note: This option is not supported yet.
    name: A name for the operation (optional).

  Returns:
    A list of `Tensor` objects of type `component_types`.
  """
  ...

QueueDequeue = ...
def queue_dequeue_eager_fallback(handle: Annotated[Any, _atypes.String], component_types, timeout_ms: int, name, ctx):
  ...

def queue_dequeue_many(handle: Annotated[Any, _atypes.String], n: Annotated[Any, _atypes.Int32], component_types, timeout_ms: int = ..., name=...): # -> tuple[Any, ...] | list[Any]:
  r"""Dequeues `n` tuples of one or more tensors from the given queue.

  If the queue is closed and there are fewer than `n` elements, then an
  OutOfRange error is returned.

  This operation concatenates queue-element component tensors along the
  0th dimension to make a single component tensor.  All of the components
  in the dequeued tuple will have size `n` in the 0th dimension.

  This operation has `k` outputs, where `k` is the number of components in
  the tuples stored in the given queue, and output `i` is the ith
  component of the dequeued tuple.

  N.B. If the queue is empty, this operation will block until `n` elements
  have been dequeued (or 'timeout_ms' elapses, if specified).

  Args:
    handle: A `Tensor` of type mutable `string`. The handle to a queue.
    n: A `Tensor` of type `int32`. The number of tuples to dequeue.
    component_types: A list of `tf.DTypes` that has length `>= 1`.
      The type of each component in a tuple.
    timeout_ms: An optional `int`. Defaults to `-1`.
      If the queue has fewer than n elements, this operation
      will block for up to timeout_ms milliseconds.
      Note: This option is not supported yet.
    name: A name for the operation (optional).

  Returns:
    A list of `Tensor` objects of type `component_types`.
  """
  ...

QueueDequeueMany = ...
def queue_dequeue_many_eager_fallback(handle: Annotated[Any, _atypes.String], n: Annotated[Any, _atypes.Int32], component_types, timeout_ms: int, name, ctx):
  ...

def queue_dequeue_many_v2(handle: Annotated[Any, _atypes.Resource], n: Annotated[Any, _atypes.Int32], component_types, timeout_ms: int = ..., name=...): # -> object | Operation | tuple[Any, ...] | list[Any]:
  r"""Dequeues `n` tuples of one or more tensors from the given queue.

  If the queue is closed and there are fewer than `n` elements, then an
  OutOfRange error is returned.

  This operation concatenates queue-element component tensors along the
  0th dimension to make a single component tensor.  All of the components
  in the dequeued tuple will have size `n` in the 0th dimension.

  This operation has `k` outputs, where `k` is the number of components in
  the tuples stored in the given queue, and output `i` is the ith
  component of the dequeued tuple.

  N.B. If the queue is empty, this operation will block until `n` elements
  have been dequeued (or 'timeout_ms' elapses, if specified).

  Args:
    handle: A `Tensor` of type `resource`. The handle to a queue.
    n: A `Tensor` of type `int32`. The number of tuples to dequeue.
    component_types: A list of `tf.DTypes` that has length `>= 1`.
      The type of each component in a tuple.
    timeout_ms: An optional `int`. Defaults to `-1`.
      If the queue has fewer than n elements, this operation
      will block for up to timeout_ms milliseconds.
      Note: This option is not supported yet.
    name: A name for the operation (optional).

  Returns:
    A list of `Tensor` objects of type `component_types`.
  """
  ...

QueueDequeueManyV2 = ...
def queue_dequeue_many_v2_eager_fallback(handle: Annotated[Any, _atypes.Resource], n: Annotated[Any, _atypes.Int32], component_types, timeout_ms: int, name, ctx): # -> object:
  ...

def queue_dequeue_up_to(handle: Annotated[Any, _atypes.String], n: Annotated[Any, _atypes.Int32], component_types, timeout_ms: int = ..., name=...): # -> tuple[Any, ...] | list[Any]:
  r"""Dequeues `n` tuples of one or more tensors from the given queue.

  This operation is not supported by all queues.  If a queue does not support
  DequeueUpTo, then an Unimplemented error is returned.

  If the queue is closed and there are more than 0 but less than `n`
  elements remaining, then instead of returning an OutOfRange error like
  QueueDequeueMany, less than `n` elements are returned immediately.  If
  the queue is closed and there are 0 elements left in the queue, then
  an OutOfRange error is returned just like in QueueDequeueMany.
  Otherwise the behavior is identical to QueueDequeueMany:

  This operation concatenates queue-element component tensors along the
  0th dimension to make a single component tensor.  All of the components
  in the dequeued tuple will have size `n` in the 0th dimension.

  This operation has k outputs, where `k` is the number of components in
  the tuples stored in the given queue, and output `i` is the ith
  component of the dequeued tuple.

  Args:
    handle: A `Tensor` of type mutable `string`. The handle to a queue.
    n: A `Tensor` of type `int32`. The number of tuples to dequeue.
    component_types: A list of `tf.DTypes` that has length `>= 1`.
      The type of each component in a tuple.
    timeout_ms: An optional `int`. Defaults to `-1`.
      If the queue has fewer than n elements, this operation
      will block for up to timeout_ms milliseconds.
      Note: This option is not supported yet.
    name: A name for the operation (optional).

  Returns:
    A list of `Tensor` objects of type `component_types`.
  """
  ...

QueueDequeueUpTo = ...
def queue_dequeue_up_to_eager_fallback(handle: Annotated[Any, _atypes.String], n: Annotated[Any, _atypes.Int32], component_types, timeout_ms: int, name, ctx):
  ...

def queue_dequeue_up_to_v2(handle: Annotated[Any, _atypes.Resource], n: Annotated[Any, _atypes.Int32], component_types, timeout_ms: int = ..., name=...): # -> object | Operation | tuple[Any, ...] | list[Any]:
  r"""Dequeues `n` tuples of one or more tensors from the given queue.

  This operation is not supported by all queues.  If a queue does not support
  DequeueUpTo, then an Unimplemented error is returned.

  If the queue is closed and there are more than 0 but less than `n`
  elements remaining, then instead of returning an OutOfRange error like
  QueueDequeueMany, less than `n` elements are returned immediately.  If
  the queue is closed and there are 0 elements left in the queue, then
  an OutOfRange error is returned just like in QueueDequeueMany.
  Otherwise the behavior is identical to QueueDequeueMany:

  This operation concatenates queue-element component tensors along the
  0th dimension to make a single component tensor.  All of the components
  in the dequeued tuple will have size n in the 0th dimension.

  This operation has `k` outputs, where `k` is the number of components in
  the tuples stored in the given queue, and output `i` is the ith
  component of the dequeued tuple.

  Args:
    handle: A `Tensor` of type `resource`. The handle to a queue.
    n: A `Tensor` of type `int32`. The number of tuples to dequeue.
    component_types: A list of `tf.DTypes` that has length `>= 1`.
      The type of each component in a tuple.
    timeout_ms: An optional `int`. Defaults to `-1`.
      If the queue has fewer than n elements, this operation
      will block for up to timeout_ms milliseconds.
      Note: This option is not supported yet.
    name: A name for the operation (optional).

  Returns:
    A list of `Tensor` objects of type `component_types`.
  """
  ...

QueueDequeueUpToV2 = ...
def queue_dequeue_up_to_v2_eager_fallback(handle: Annotated[Any, _atypes.Resource], n: Annotated[Any, _atypes.Int32], component_types, timeout_ms: int, name, ctx): # -> object:
  ...

def queue_dequeue_v2(handle: Annotated[Any, _atypes.Resource], component_types, timeout_ms: int = ..., name=...): # -> object | Operation | tuple[Any, ...] | list[Any]:
  r"""Dequeues a tuple of one or more tensors from the given queue.

  This operation has k outputs, where k is the number of components
  in the tuples stored in the given queue, and output i is the ith
  component of the dequeued tuple.

  N.B. If the queue is empty, this operation will block until an element
  has been dequeued (or 'timeout_ms' elapses, if specified).

  Args:
    handle: A `Tensor` of type `resource`. The handle to a queue.
    component_types: A list of `tf.DTypes` that has length `>= 1`.
      The type of each component in a tuple.
    timeout_ms: An optional `int`. Defaults to `-1`.
      If the queue is empty, this operation will block for up to
      timeout_ms milliseconds.
      Note: This option is not supported yet.
    name: A name for the operation (optional).

  Returns:
    A list of `Tensor` objects of type `component_types`.
  """
  ...

QueueDequeueV2 = ...
def queue_dequeue_v2_eager_fallback(handle: Annotated[Any, _atypes.Resource], component_types, timeout_ms: int, name, ctx): # -> object:
  ...

def queue_enqueue(handle: Annotated[Any, _atypes.String], components, timeout_ms: int = ..., name=...): # -> Operation:
  r"""Enqueues a tuple of one or more tensors in the given queue.

  The components input has k elements, which correspond to the components of
  tuples stored in the given queue.

  N.B. If the queue is full, this operation will block until the given
  element has been enqueued (or 'timeout_ms' elapses, if specified).

  Args:
    handle: A `Tensor` of type mutable `string`. The handle to a queue.
    components: A list of `Tensor` objects.
      One or more tensors from which the enqueued tensors should be taken.
    timeout_ms: An optional `int`. Defaults to `-1`.
      If the queue is full, this operation will block for up to
      timeout_ms milliseconds.
      Note: This option is not supported yet.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

QueueEnqueue = ...
def queue_enqueue_eager_fallback(handle: Annotated[Any, _atypes.String], components, timeout_ms: int, name, ctx):
  ...

def queue_enqueue_many(handle: Annotated[Any, _atypes.String], components, timeout_ms: int = ..., name=...): # -> Operation:
  r"""Enqueues zero or more tuples of one or more tensors in the given queue.

  This operation slices each component tensor along the 0th dimension to
  make multiple queue elements. All of the tuple components must have the
  same size in the 0th dimension.

  The components input has k elements, which correspond to the components of
  tuples stored in the given queue.

  N.B. If the queue is full, this operation will block until the given
  elements have been enqueued (or 'timeout_ms' elapses, if specified).

  Args:
    handle: A `Tensor` of type mutable `string`. The handle to a queue.
    components: A list of `Tensor` objects.
      One or more tensors from which the enqueued tensors should
      be taken.
    timeout_ms: An optional `int`. Defaults to `-1`.
      If the queue is too full, this operation will block for up
      to timeout_ms milliseconds.
      Note: This option is not supported yet.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

QueueEnqueueMany = ...
def queue_enqueue_many_eager_fallback(handle: Annotated[Any, _atypes.String], components, timeout_ms: int, name, ctx):
  ...

def queue_enqueue_many_v2(handle: Annotated[Any, _atypes.Resource], components, timeout_ms: int = ..., name=...): # -> object | Operation | None:
  r"""Enqueues zero or more tuples of one or more tensors in the given queue.

  This operation slices each component tensor along the 0th dimension to
  make multiple queue elements. All of the tuple components must have the
  same size in the 0th dimension.

  The components input has k elements, which correspond to the components of
  tuples stored in the given queue.

  N.B. If the queue is full, this operation will block until the given
  elements have been enqueued (or 'timeout_ms' elapses, if specified).

  Args:
    handle: A `Tensor` of type `resource`. The handle to a queue.
    components: A list of `Tensor` objects.
      One or more tensors from which the enqueued tensors should
      be taken.
    timeout_ms: An optional `int`. Defaults to `-1`.
      If the queue is too full, this operation will block for up
      to timeout_ms milliseconds.
      Note: This option is not supported yet.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

QueueEnqueueManyV2 = ...
def queue_enqueue_many_v2_eager_fallback(handle: Annotated[Any, _atypes.Resource], components, timeout_ms: int, name, ctx): # -> None:
  ...

def queue_enqueue_v2(handle: Annotated[Any, _atypes.Resource], components, timeout_ms: int = ..., name=...): # -> object | Operation | None:
  r"""Enqueues a tuple of one or more tensors in the given queue.

  The components input has k elements, which correspond to the components of
  tuples stored in the given queue.

  N.B. If the queue is full, this operation will block until the given
  element has been enqueued (or 'timeout_ms' elapses, if specified).

  Args:
    handle: A `Tensor` of type `resource`. The handle to a queue.
    components: A list of `Tensor` objects.
      One or more tensors from which the enqueued tensors should be taken.
    timeout_ms: An optional `int`. Defaults to `-1`.
      If the queue is full, this operation will block for up to
      timeout_ms milliseconds.
      Note: This option is not supported yet.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

QueueEnqueueV2 = ...
def queue_enqueue_v2_eager_fallback(handle: Annotated[Any, _atypes.Resource], components, timeout_ms: int, name, ctx): # -> None:
  ...

def queue_is_closed(handle: Annotated[Any, _atypes.String], name=...) -> Annotated[Any, _atypes.Bool]:
  r"""Returns true if queue is closed.

  This operation returns true if the queue is closed and false if the queue
  is open.

  Args:
    handle: A `Tensor` of type mutable `string`. The handle to a queue.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `bool`.
  """
  ...

QueueIsClosed = ...
def queue_is_closed_eager_fallback(handle: Annotated[Any, _atypes.String], name, ctx) -> Annotated[Any, _atypes.Bool]:
  ...

def queue_is_closed_v2(handle: Annotated[Any, _atypes.Resource], name=...) -> Annotated[Any, _atypes.Bool]:
  r"""Returns true if queue is closed.

  This operation returns true if the queue is closed and false if the queue
  is open.

  Args:
    handle: A `Tensor` of type `resource`. The handle to a queue.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `bool`.
  """
  ...

QueueIsClosedV2 = ...
def queue_is_closed_v2_eager_fallback(handle: Annotated[Any, _atypes.Resource], name, ctx) -> Annotated[Any, _atypes.Bool]:
  ...

def queue_size(handle: Annotated[Any, _atypes.String], name=...) -> Annotated[Any, _atypes.Int32]:
  r"""Computes the number of elements in the given queue.

  Args:
    handle: A `Tensor` of type mutable `string`. The handle to a queue.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int32`.
  """
  ...

QueueSize = ...
def queue_size_eager_fallback(handle: Annotated[Any, _atypes.String], name, ctx) -> Annotated[Any, _atypes.Int32]:
  ...

def queue_size_v2(handle: Annotated[Any, _atypes.Resource], name=...) -> Annotated[Any, _atypes.Int32]:
  r"""Computes the number of elements in the given queue.

  Args:
    handle: A `Tensor` of type `resource`. The handle to a queue.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int32`.
  """
  ...

QueueSizeV2 = ...
def queue_size_v2_eager_fallback(handle: Annotated[Any, _atypes.Resource], name, ctx) -> Annotated[Any, _atypes.Int32]:
  ...

def random_shuffle_queue(component_types, shapes=..., capacity: int = ..., min_after_dequeue: int = ..., seed: int = ..., seed2: int = ..., container: str = ..., shared_name: str = ..., name=...) -> Annotated[Any, _atypes.String]:
  r"""A queue that randomizes the order of elements.

  Args:
    component_types: A list of `tf.DTypes` that has length `>= 1`.
      The type of each component in a value.
    shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
      The shape of each component in a value. The length of this attr must
      be either 0 or the same as the length of component_types. If the length of
      this attr is 0, the shapes of queue elements are not constrained, and
      only one element may be dequeued at a time.
    capacity: An optional `int`. Defaults to `-1`.
      The upper bound on the number of elements in this queue.
      Negative numbers mean no limit.
    min_after_dequeue: An optional `int`. Defaults to `0`.
      Dequeue will block unless there would be this
      many elements after the dequeue or the queue is closed. This
      ensures a minimum level of mixing of elements.
    seed: An optional `int`. Defaults to `0`.
      If either seed or seed2 is set to be non-zero, the random number
      generator is seeded by the given seed.  Otherwise, a random seed is used.
    seed2: An optional `int`. Defaults to `0`.
      A second seed to avoid seed collision.
    container: An optional `string`. Defaults to `""`.
      If non-empty, this queue is placed in the given container.
      Otherwise, a default container is used.
    shared_name: An optional `string`. Defaults to `""`.
      If non-empty, this queue will be shared under the given name
      across multiple sessions.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type mutable `string`.
  """
  ...

RandomShuffleQueue = ...
def random_shuffle_queue_eager_fallback(component_types, shapes, capacity: int, min_after_dequeue: int, seed: int, seed2: int, container: str, shared_name: str, name, ctx) -> Annotated[Any, _atypes.String]:
  ...

def random_shuffle_queue_v2(component_types, shapes=..., capacity: int = ..., min_after_dequeue: int = ..., seed: int = ..., seed2: int = ..., container: str = ..., shared_name: str = ..., name=...) -> Annotated[Any, _atypes.Resource]:
  r"""A queue that randomizes the order of elements.

  Args:
    component_types: A list of `tf.DTypes` that has length `>= 1`.
      The type of each component in a value.
    shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
      The shape of each component in a value. The length of this attr must
      be either 0 or the same as the length of component_types. If the length of
      this attr is 0, the shapes of queue elements are not constrained, and
      only one element may be dequeued at a time.
    capacity: An optional `int`. Defaults to `-1`.
      The upper bound on the number of elements in this queue.
      Negative numbers mean no limit.
    min_after_dequeue: An optional `int`. Defaults to `0`.
      Dequeue will block unless there would be this
      many elements after the dequeue or the queue is closed. This
      ensures a minimum level of mixing of elements.
    seed: An optional `int`. Defaults to `0`.
      If either seed or seed2 is set to be non-zero, the random number
      generator is seeded by the given seed.  Otherwise, a random seed is used.
    seed2: An optional `int`. Defaults to `0`.
      A second seed to avoid seed collision.
    container: An optional `string`. Defaults to `""`.
      If non-empty, this queue is placed in the given container.
      Otherwise, a default container is used.
    shared_name: An optional `string`. Defaults to `""`.
      If non-empty, this queue will be shared under the given name
      across multiple sessions.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `resource`.
  """
  ...

RandomShuffleQueueV2 = ...
def random_shuffle_queue_v2_eager_fallback(component_types, shapes, capacity: int, min_after_dequeue: int, seed: int, seed2: int, container: str, shared_name: str, name, ctx) -> Annotated[Any, _atypes.Resource]:
  ...

def record_input(file_pattern: str, file_random_seed: int = ..., file_shuffle_shift_ratio: float = ..., file_buffer_size: int = ..., file_parallelism: int = ..., batch_size: int = ..., compression_type: str = ..., name=...) -> Annotated[Any, _atypes.String]:
  r"""Emits randomized records.

  Args:
    file_pattern: A `string`. Glob pattern for the data files.
    file_random_seed: An optional `int`. Defaults to `301`.
      Random seeds used to produce randomized records.
    file_shuffle_shift_ratio: An optional `float`. Defaults to `0`.
      Shifts the list of files after the list is randomly
      shuffled.
    file_buffer_size: An optional `int`. Defaults to `10000`.
      The randomization shuffling buffer.
    file_parallelism: An optional `int`. Defaults to `16`.
      How many sstables are opened and concurrently iterated over.
    batch_size: An optional `int`. Defaults to `32`. The batch size.
    compression_type: An optional `string`. Defaults to `""`.
      The type of compression for the file. Currently ZLIB and
      GZIP are supported. Defaults to none.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `string`.
  """
  ...

RecordInput = ...
def record_input_eager_fallback(file_pattern: str, file_random_seed: int, file_shuffle_shift_ratio: float, file_buffer_size: int, file_parallelism: int, batch_size: int, compression_type: str, name, ctx) -> Annotated[Any, _atypes.String]:
  ...

TV_ResourceAccumulatorApplyGradient_dtype = TypeVar("TV_ResourceAccumulatorApplyGradient_dtype", _atypes.BFloat16, _atypes.Complex128, _atypes.Complex64, _atypes.Float32, _atypes.Float64, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.UInt16, _atypes.UInt32, _atypes.UInt64, _atypes.UInt8)
def resource_accumulator_apply_gradient(handle: Annotated[Any, _atypes.Resource], local_step: Annotated[Any, _atypes.Int64], gradient: Annotated[Any, TV_ResourceAccumulatorApplyGradient_dtype], name=...): # -> object | Operation | None:
  r"""Applies a gradient to a given accumulator.

  Does not add if local_step is lesser than the accumulator's global_step.

  Args:
    handle: A `Tensor` of type `resource`. The handle to a accumulator.
    local_step: A `Tensor` of type `int64`.
      The local_step value at which the gradient was computed.
    gradient: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `qint16`, `quint16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
      A tensor of the gradient to be accumulated.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

ResourceAccumulatorApplyGradient = ...
def resource_accumulator_apply_gradient_eager_fallback(handle: Annotated[Any, _atypes.Resource], local_step: Annotated[Any, _atypes.Int64], gradient: Annotated[Any, TV_ResourceAccumulatorApplyGradient_dtype], name, ctx): # -> None:
  ...

def resource_accumulator_num_accumulated(handle: Annotated[Any, _atypes.Resource], name=...) -> Annotated[Any, _atypes.Int32]:
  r"""Returns the number of gradients aggregated in the given accumulators.

  Args:
    handle: A `Tensor` of type `resource`. The handle to an accumulator.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int32`.
  """
  ...

ResourceAccumulatorNumAccumulated = ...
def resource_accumulator_num_accumulated_eager_fallback(handle: Annotated[Any, _atypes.Resource], name, ctx) -> Annotated[Any, _atypes.Int32]:
  ...

def resource_accumulator_set_global_step(handle: Annotated[Any, _atypes.Resource], new_global_step: Annotated[Any, _atypes.Int64], name=...): # -> object | Operation | None:
  r"""Updates the accumulator with a new value for global_step.

  Logs warning if the accumulator's value is already higher than
  new_global_step.

  Args:
    handle: A `Tensor` of type `resource`. The handle to an accumulator.
    new_global_step: A `Tensor` of type `int64`.
      The new global_step value to set.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

ResourceAccumulatorSetGlobalStep = ...
def resource_accumulator_set_global_step_eager_fallback(handle: Annotated[Any, _atypes.Resource], new_global_step: Annotated[Any, _atypes.Int64], name, ctx): # -> None:
  ...

TV_ResourceAccumulatorTakeGradient_dtype = TypeVar("TV_ResourceAccumulatorTakeGradient_dtype", _atypes.BFloat16, _atypes.Complex128, _atypes.Complex64, _atypes.Float32, _atypes.Float64, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.UInt16, _atypes.UInt32, _atypes.UInt64, _atypes.UInt8)
def resource_accumulator_take_gradient(handle: Annotated[Any, _atypes.Resource], num_required: Annotated[Any, _atypes.Int32], dtype: TV_ResourceAccumulatorTakeGradient_dtype, name=...) -> Annotated[Any, TV_ResourceAccumulatorTakeGradient_dtype]:
  r"""Extracts the average gradient in the given ConditionalAccumulator.

  The op blocks until sufficient (i.e., more than num_required)
  gradients have been accumulated.  If the accumulator has already
  aggregated more than num_required gradients, it returns the average of
  the accumulated gradients.  Also automatically increments the recorded
  global_step in the accumulator by 1, and resets the aggregate to 0.

  Args:
    handle: A `Tensor` of type `resource`. The handle to an accumulator.
    num_required: A `Tensor` of type `int32`.
      Number of gradients required before we return an aggregate.
    dtype: A `tf.DType` from: `tf.float32, tf.float64, tf.int32, tf.uint8, tf.int16, tf.int8, tf.complex64, tf.int64, tf.qint8, tf.quint8, tf.qint32, tf.bfloat16, tf.qint16, tf.quint16, tf.uint16, tf.complex128, tf.half, tf.uint32, tf.uint64`.
      The data type of accumulated gradients. Needs to correspond to the type
      of the accumulator.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `dtype`.
  """
  ...

ResourceAccumulatorTakeGradient = ...
def resource_accumulator_take_gradient_eager_fallback(handle: Annotated[Any, _atypes.Resource], num_required: Annotated[Any, _atypes.Int32], dtype: TV_ResourceAccumulatorTakeGradient_dtype, name, ctx) -> Annotated[Any, TV_ResourceAccumulatorTakeGradient_dtype]:
  ...

TV_ResourceConditionalAccumulator_dtype = TypeVar("TV_ResourceConditionalAccumulator_dtype", _atypes.BFloat16, _atypes.Complex128, _atypes.Complex64, _atypes.Float32, _atypes.Float64, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.UInt16, _atypes.UInt32, _atypes.UInt64, _atypes.UInt8)
def resource_conditional_accumulator(dtype: TV_ResourceConditionalAccumulator_dtype, shape, container: str = ..., shared_name: str = ..., reduction_type: str = ..., name=...) -> Annotated[Any, _atypes.Resource]:
  r"""A conditional accumulator for aggregating gradients.

  The accumulator accepts gradients marked with local_step greater or
  equal to the most recent global_step known to the accumulator. The
  average can be extracted from the accumulator, provided sufficient
  gradients have been accumulated. Extracting the average automatically
  resets the aggregate to 0, and increments the global_step recorded by
  the accumulator.
  This is a resource version of ConditionalAccumulator that will work in TF2.0
  with tf.cond version 2.

  Args:
    dtype: A `tf.DType` from: `tf.float32, tf.float64, tf.int32, tf.uint8, tf.int16, tf.int8, tf.complex64, tf.int64, tf.qint8, tf.quint8, tf.qint32, tf.bfloat16, tf.qint16, tf.quint16, tf.uint16, tf.complex128, tf.half, tf.uint32, tf.uint64`.
      The type of the value being accumulated.
    shape: A `tf.TensorShape` or list of `ints`.
      The shape of the values, can be [], in which case shape is unknown.
    container: An optional `string`. Defaults to `""`.
      If non-empty, this accumulator is placed in the given container.
      Otherwise, a default container is used.
    shared_name: An optional `string`. Defaults to `""`.
      If non-empty, this accumulator will be shared under the
      given name across multiple sessions.
    reduction_type: An optional `string` from: `"MEAN", "SUM"`. Defaults to `"MEAN"`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `resource`.
  """
  ...

ResourceConditionalAccumulator = ...
def resource_conditional_accumulator_eager_fallback(dtype: TV_ResourceConditionalAccumulator_dtype, shape, container: str, shared_name: str, reduction_type: str, name, ctx) -> Annotated[Any, _atypes.Resource]:
  ...

TV_SparseAccumulatorApplyGradient_dtype = TypeVar("TV_SparseAccumulatorApplyGradient_dtype", _atypes.BFloat16, _atypes.Complex128, _atypes.Complex64, _atypes.Float32, _atypes.Float64, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.UInt16, _atypes.UInt32, _atypes.UInt64, _atypes.UInt8)
def sparse_accumulator_apply_gradient(handle: Annotated[Any, _atypes.String], local_step: Annotated[Any, _atypes.Int64], gradient_indices: Annotated[Any, _atypes.Int64], gradient_values: Annotated[Any, TV_SparseAccumulatorApplyGradient_dtype], gradient_shape: Annotated[Any, _atypes.Int64], has_known_shape: bool, name=...): # -> Operation:
  r"""Applies a sparse gradient to a given accumulator.

  Does not add if local_step is smaller than the accumulator's
  global_step.

  Args:
    handle: A `Tensor` of type mutable `string`. The handle to a accumulator.
    local_step: A `Tensor` of type `int64`.
      The local_step value at which the sparse gradient was computed.
    gradient_indices: A `Tensor` of type `int64`.
      Indices of the sparse gradient to be accumulated. Must be a
      vector.
    gradient_values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `qint16`, `quint16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
      Values are the non-zero slices of the gradient, and must have
      the same first dimension as indices, i.e., the nnz represented by indices and
      values must be consistent.
    gradient_shape: A `Tensor` of type `int64`.
      Shape of the sparse gradient to be accumulated.
    has_known_shape: A `bool`.
      Boolean indicating whether gradient_shape is unknown, in which
      case the input is ignored during validation.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

SparseAccumulatorApplyGradient = ...
def sparse_accumulator_apply_gradient_eager_fallback(handle: Annotated[Any, _atypes.String], local_step: Annotated[Any, _atypes.Int64], gradient_indices: Annotated[Any, _atypes.Int64], gradient_values: Annotated[Any, TV_SparseAccumulatorApplyGradient_dtype], gradient_shape: Annotated[Any, _atypes.Int64], has_known_shape: bool, name, ctx):
  ...

_SparseAccumulatorTakeGradientOutput = ...
TV_SparseAccumulatorTakeGradient_dtype = TypeVar("TV_SparseAccumulatorTakeGradient_dtype", _atypes.BFloat16, _atypes.Complex128, _atypes.Complex64, _atypes.Float32, _atypes.Float64, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.UInt16, _atypes.UInt32, _atypes.UInt64, _atypes.UInt8)
def sparse_accumulator_take_gradient(handle: Annotated[Any, _atypes.String], num_required: Annotated[Any, _atypes.Int32], dtype: TV_SparseAccumulatorTakeGradient_dtype, name=...): # -> SparseAccumulatorTakeGradient:
  r"""Extracts the average sparse gradient in a SparseConditionalAccumulator.

  The op will blocks until sufficient (i.e., more than num_required)
  gradients have been accumulated. If the accumulator has already
  aggregated more than num_required gradients, it will return its
  average of the accumulated gradients.  Also automatically increments
  the recorded global_step in the accumulator by 1, and resets the
  aggregate to 0.

  Args:
    handle: A `Tensor` of type mutable `string`.
      The handle to a SparseConditionalAccumulator.
    num_required: A `Tensor` of type `int32`.
      Number of gradients required before we return an aggregate.
    dtype: A `tf.DType` from: `tf.float32, tf.float64, tf.int32, tf.uint8, tf.int16, tf.int8, tf.complex64, tf.int64, tf.qint8, tf.quint8, tf.qint32, tf.bfloat16, tf.qint16, tf.quint16, tf.uint16, tf.complex128, tf.half, tf.uint32, tf.uint64`.
      The data type of accumulated gradients. Needs to correspond to the type
      of the accumulator.
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (indices, values, shape).

    indices: A `Tensor` of type `int64`.
    values: A `Tensor` of type `dtype`.
    shape: A `Tensor` of type `int64`.
  """
  ...

SparseAccumulatorTakeGradient = ...
def sparse_accumulator_take_gradient_eager_fallback(handle: Annotated[Any, _atypes.String], num_required: Annotated[Any, _atypes.Int32], dtype: TV_SparseAccumulatorTakeGradient_dtype, name, ctx):
  ...

TV_SparseConditionalAccumulator_dtype = TypeVar("TV_SparseConditionalAccumulator_dtype", _atypes.BFloat16, _atypes.Complex128, _atypes.Complex64, _atypes.Float32, _atypes.Float64, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.UInt16, _atypes.UInt32, _atypes.UInt64, _atypes.UInt8)
def sparse_conditional_accumulator(dtype: TV_SparseConditionalAccumulator_dtype, shape, container: str = ..., shared_name: str = ..., reduction_type: str = ..., name=...) -> Annotated[Any, _atypes.String]:
  r"""A conditional accumulator for aggregating sparse gradients.

  The accumulator accepts gradients marked with local_step greater or
  equal to the most recent global_step known to the accumulator. The
  average can be extracted from the accumulator, provided sufficient
  gradients have been accumulated. Extracting the average automatically
  resets the aggregate to 0, and increments the global_step recorded by
  the accumulator.

  Args:
    dtype: A `tf.DType` from: `tf.float32, tf.float64, tf.int32, tf.uint8, tf.int16, tf.int8, tf.complex64, tf.int64, tf.qint8, tf.quint8, tf.qint32, tf.bfloat16, tf.qint16, tf.quint16, tf.uint16, tf.complex128, tf.half, tf.uint32, tf.uint64`.
      The type of the value being accumulated.
    shape: A `tf.TensorShape` or list of `ints`. The shape of the values.
    container: An optional `string`. Defaults to `""`.
      If non-empty, this accumulator is placed in the given container.
      Otherwise, a default container is used.
    shared_name: An optional `string`. Defaults to `""`.
      If non-empty, this accumulator will be shared under the given name
      across multiple sessions.
    reduction_type: An optional `string` from: `"MEAN", "SUM"`. Defaults to `"MEAN"`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type mutable `string`.
  """
  ...

SparseConditionalAccumulator = ...
def sparse_conditional_accumulator_eager_fallback(dtype: TV_SparseConditionalAccumulator_dtype, shape, container: str, shared_name: str, reduction_type: str, name, ctx) -> Annotated[Any, _atypes.String]:
  ...

TV_Stack_elem_type = TypeVar("TV_Stack_elem_type", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
Stack = ...
def stack_close(handle: Annotated[Any, _atypes.String], name=...): # -> Operation:
  r"""Deprecated, use StackCloseV2.

  Args:
    handle: A `Tensor` of type mutable `string`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

StackClose = ...
def stack_close_eager_fallback(handle: Annotated[Any, _atypes.String], name, ctx):
  ...

def stack_close_v2(handle: Annotated[Any, _atypes.Resource], name=...): # -> object | Operation | None:
  r"""Delete the stack from its resource container.

  Args:
    handle: A `Tensor` of type `resource`. The handle to a stack.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

StackCloseV2 = ...
def stack_close_v2_eager_fallback(handle: Annotated[Any, _atypes.Resource], name, ctx): # -> None:
  ...

TV_StackPop_elem_type = TypeVar("TV_StackPop_elem_type", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def stack_pop(handle: Annotated[Any, _atypes.String], elem_type: TV_StackPop_elem_type, name=...) -> Annotated[Any, TV_StackPop_elem_type]:
  r"""Deprecated, use StackPopV2.

  Args:
    handle: A `Tensor` of type mutable `string`.
    elem_type: A `tf.DType`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `elem_type`.
  """
  ...

StackPop = ...
def stack_pop_eager_fallback(handle: Annotated[Any, _atypes.String], elem_type: TV_StackPop_elem_type, name, ctx) -> Annotated[Any, TV_StackPop_elem_type]:
  ...

TV_StackPopV2_elem_type = TypeVar("TV_StackPopV2_elem_type", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def stack_pop_v2(handle: Annotated[Any, _atypes.Resource], elem_type: TV_StackPopV2_elem_type, name=...) -> Annotated[Any, TV_StackPopV2_elem_type]:
  r"""Pop the element at the top of the stack.

  Args:
    handle: A `Tensor` of type `resource`. The handle to a stack.
    elem_type: A `tf.DType`. The type of the elem that is popped.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `elem_type`.
  """
  ...

StackPopV2 = ...
def stack_pop_v2_eager_fallback(handle: Annotated[Any, _atypes.Resource], elem_type: TV_StackPopV2_elem_type, name, ctx) -> Annotated[Any, TV_StackPopV2_elem_type]:
  ...

TV_StackPush_T = TypeVar("TV_StackPush_T", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def stack_push(handle: Annotated[Any, _atypes.String], elem: Annotated[Any, TV_StackPush_T], swap_memory: bool = ..., name=...) -> Annotated[Any, TV_StackPush_T]:
  r"""Deprecated, use StackPushV2.

  Args:
    handle: A `Tensor` of type mutable `string`.
    elem: A `Tensor`.
    swap_memory: An optional `bool`. Defaults to `False`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor`. Has the same type as `elem`.
  """
  ...

StackPush = ...
def stack_push_eager_fallback(handle: Annotated[Any, _atypes.String], elem: Annotated[Any, TV_StackPush_T], swap_memory: bool, name, ctx) -> Annotated[Any, TV_StackPush_T]:
  ...

TV_StackPushV2_T = TypeVar("TV_StackPushV2_T", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def stack_push_v2(handle: Annotated[Any, _atypes.Resource], elem: Annotated[Any, TV_StackPushV2_T], swap_memory: bool = ..., name=...) -> Annotated[Any, TV_StackPushV2_T]:
  r"""Push an element onto the stack.

  Args:
    handle: A `Tensor` of type `resource`. The handle to a stack.
    elem: A `Tensor`. The tensor to be pushed onto the stack.
    swap_memory: An optional `bool`. Defaults to `False`.
      Swap `elem` to CPU. Default to false.
    name: A name for the operation (optional).

  Returns:
    A `Tensor`. Has the same type as `elem`.
  """
  ...

StackPushV2 = ...
def stack_push_v2_eager_fallback(handle: Annotated[Any, _atypes.Resource], elem: Annotated[Any, TV_StackPushV2_T], swap_memory: bool, name, ctx) -> Annotated[Any, TV_StackPushV2_T]:
  ...

TV_StackV2_elem_type = TypeVar("TV_StackV2_elem_type", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def stack_v2(max_size: Annotated[Any, _atypes.Int32], elem_type: TV_StackV2_elem_type, stack_name: str = ..., name=...) -> Annotated[Any, _atypes.Resource]:
  r"""A stack that produces elements in first-in last-out order.

  Args:
    max_size: A `Tensor` of type `int32`.
      The maximum size of the stack if non-negative. If negative, the stack
      size is unlimited.
    elem_type: A `tf.DType`. The type of the elements on the stack.
    stack_name: An optional `string`. Defaults to `""`.
      Overrides the name used for the temporary stack resource. Default
      value is the name of the 'Stack' op (which is guaranteed unique).
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `resource`.
  """
  ...

StackV2 = ...
def stack_v2_eager_fallback(max_size: Annotated[Any, _atypes.Int32], elem_type: TV_StackV2_elem_type, stack_name: str, name, ctx) -> Annotated[Any, _atypes.Resource]:
  ...

def stage(values, capacity: int = ..., memory_limit: int = ..., container: str = ..., shared_name: str = ..., name=...): # -> object | Operation | None:
  r"""Stage values similar to a lightweight Enqueue.

  The basic functionality of this Op is similar to a queue with many
  fewer capabilities and options.  This Op is optimized for performance.

  Args:
    values: A list of `Tensor` objects. a list of tensors
      dtypes A list of data types that inserted values should adhere to.
    capacity: An optional `int` that is `>= 0`. Defaults to `0`.
      Maximum number of elements in the Staging Area. If > 0, inserts
      on the container will block when the capacity is reached.
    memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
      The maximum number of bytes allowed for Tensors in the Staging Area.
      If > 0, inserts will block until sufficient space is available.
    container: An optional `string`. Defaults to `""`.
      If non-empty, this queue is placed in the given container. Otherwise,
      a default container is used.
    shared_name: An optional `string`. Defaults to `""`.
      It is necessary to match this name to the matching Unstage Op.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

Stage = ...
def stage_eager_fallback(values, capacity: int, memory_limit: int, container: str, shared_name: str, name, ctx): # -> None:
  ...

def stage_clear(dtypes, capacity: int = ..., memory_limit: int = ..., container: str = ..., shared_name: str = ..., name=...): # -> object | Operation | None:
  r"""Op removes all elements in the underlying container.

  Args:
    dtypes: A list of `tf.DTypes`.
    capacity: An optional `int` that is `>= 0`. Defaults to `0`.
    memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
    container: An optional `string`. Defaults to `""`.
    shared_name: An optional `string`. Defaults to `""`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

StageClear = ...
def stage_clear_eager_fallback(dtypes, capacity: int, memory_limit: int, container: str, shared_name: str, name, ctx): # -> None:
  ...

def stage_peek(index: Annotated[Any, _atypes.Int32], dtypes, capacity: int = ..., memory_limit: int = ..., container: str = ..., shared_name: str = ..., name=...): # -> object | Operation | tuple[Any, ...] | list[Any]:
  r"""Op peeks at the values at the specified index.  If the

  underlying container does not contain sufficient elements
  this op will block until it does.   This Op is optimized for
  performance.

  Args:
    index: A `Tensor` of type `int32`.
    dtypes: A list of `tf.DTypes` that has length `>= 1`.
    capacity: An optional `int` that is `>= 0`. Defaults to `0`.
    memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
    container: An optional `string`. Defaults to `""`.
    shared_name: An optional `string`. Defaults to `""`.
    name: A name for the operation (optional).

  Returns:
    A list of `Tensor` objects of type `dtypes`.
  """
  ...

StagePeek = ...
def stage_peek_eager_fallback(index: Annotated[Any, _atypes.Int32], dtypes, capacity: int, memory_limit: int, container: str, shared_name: str, name, ctx): # -> object:
  ...

def stage_size(dtypes, capacity: int = ..., memory_limit: int = ..., container: str = ..., shared_name: str = ..., name=...) -> Annotated[Any, _atypes.Int32]:
  r"""Op returns the number of elements in the underlying container.

  Args:
    dtypes: A list of `tf.DTypes`.
    capacity: An optional `int` that is `>= 0`. Defaults to `0`.
    memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
    container: An optional `string`. Defaults to `""`.
    shared_name: An optional `string`. Defaults to `""`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int32`.
  """
  ...

StageSize = ...
def stage_size_eager_fallback(dtypes, capacity: int, memory_limit: int, container: str, shared_name: str, name, ctx) -> Annotated[Any, _atypes.Int32]:
  ...

TV_TensorArray_dtype = TypeVar("TV_TensorArray_dtype", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array(size: Annotated[Any, _atypes.Int32], dtype: TV_TensorArray_dtype, dynamic_size: bool = ..., clear_after_read: bool = ..., tensor_array_name: str = ..., element_shape=..., name=...) -> Annotated[Any, _atypes.String]:
  r"""TODO: add doc.

  Args:
    size: A `Tensor` of type `int32`.
    dtype: A `tf.DType`.
    dynamic_size: An optional `bool`. Defaults to `False`.
    clear_after_read: An optional `bool`. Defaults to `True`.
    tensor_array_name: An optional `string`. Defaults to `""`.
    element_shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type mutable `string`.
  """
  ...

TensorArray = ...
def tensor_array_eager_fallback(size: Annotated[Any, _atypes.Int32], dtype: TV_TensorArray_dtype, dynamic_size: bool, clear_after_read: bool, tensor_array_name: str, element_shape, name, ctx) -> Annotated[Any, _atypes.String]:
  ...

def tensor_array_close(handle: Annotated[Any, _atypes.String], name=...): # -> Operation:
  r"""TODO: add doc.

  Args:
    handle: A `Tensor` of type mutable `string`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

TensorArrayClose = ...
def tensor_array_close_eager_fallback(handle: Annotated[Any, _atypes.String], name, ctx):
  ...

def tensor_array_close_v2(handle: Annotated[Any, _atypes.String], name=...): # -> object | Operation | None:
  r"""Deprecated. Use TensorArrayCloseV3

  Args:
    handle: A `Tensor` of type `string`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

TensorArrayCloseV2 = ...
def tensor_array_close_v2_eager_fallback(handle: Annotated[Any, _atypes.String], name, ctx): # -> None:
  ...

def tensor_array_close_v3(handle: Annotated[Any, _atypes.Resource], name=...): # -> object | Operation | None:
  r"""Delete the TensorArray from its resource container.

  This enables the user to close and release the resource in the middle
  of a step/run.

  Args:
    handle: A `Tensor` of type `resource`.
      The handle to a TensorArray (output of TensorArray or TensorArrayGrad).
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  ...

TensorArrayCloseV3 = ...
def tensor_array_close_v3_eager_fallback(handle: Annotated[Any, _atypes.Resource], name, ctx): # -> None:
  ...

_TensorArrayConcatOutput = ...
TV_TensorArrayConcat_dtype = TypeVar("TV_TensorArrayConcat_dtype", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array_concat(handle: Annotated[Any, _atypes.String], flow_in: Annotated[Any, _atypes.Float32], dtype: TV_TensorArrayConcat_dtype, element_shape_except0=..., name=...): # -> TensorArrayConcat:
  r"""TODO: add doc.

  Args:
    handle: A `Tensor` of type mutable `string`.
    flow_in: A `Tensor` of type `float32`.
    dtype: A `tf.DType`.
    element_shape_except0: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (value, lengths).

    value: A `Tensor` of type `dtype`.
    lengths: A `Tensor` of type `int64`.
  """
  ...

TensorArrayConcat = ...
def tensor_array_concat_eager_fallback(handle: Annotated[Any, _atypes.String], flow_in: Annotated[Any, _atypes.Float32], dtype: TV_TensorArrayConcat_dtype, element_shape_except0, name, ctx):
  ...

_TensorArrayConcatV2Output = ...
TV_TensorArrayConcatV2_dtype = TypeVar("TV_TensorArrayConcatV2_dtype", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array_concat_v2(handle: Annotated[Any, _atypes.String], flow_in: Annotated[Any, _atypes.Float32], dtype: TV_TensorArrayConcatV2_dtype, element_shape_except0=..., name=...): # -> TensorArrayConcatV2:
  r"""Deprecated. Use TensorArrayConcatV3

  Args:
    handle: A `Tensor` of type `string`.
    flow_in: A `Tensor` of type `float32`.
    dtype: A `tf.DType`.
    element_shape_except0: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (value, lengths).

    value: A `Tensor` of type `dtype`.
    lengths: A `Tensor` of type `int64`.
  """
  ...

TensorArrayConcatV2 = ...
def tensor_array_concat_v2_eager_fallback(handle: Annotated[Any, _atypes.String], flow_in: Annotated[Any, _atypes.Float32], dtype: TV_TensorArrayConcatV2_dtype, element_shape_except0, name, ctx): # -> TensorArrayConcatV2:
  ...

_TensorArrayConcatV3Output = ...
TV_TensorArrayConcatV3_dtype = TypeVar("TV_TensorArrayConcatV3_dtype", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array_concat_v3(handle: Annotated[Any, _atypes.Resource], flow_in: Annotated[Any, _atypes.Float32], dtype: TV_TensorArrayConcatV3_dtype, element_shape_except0=..., name=...): # -> TensorArrayConcatV3:
  r"""Concat the elements from the TensorArray into value `value`.

  Takes `T` elements of shapes

    ```
    (n0 x d0 x d1 x ...), (n1 x d0 x d1 x ...), ..., (n(T-1) x d0 x d1 x ...)
    ```

  and concatenates them into a Tensor of shape:

    ```
    (n0 + n1 + ... + n(T-1) x d0 x d1 x ...)
    ```

  All elements must have the same shape (excepting the first dimension).

  Args:
    handle: A `Tensor` of type `resource`. The handle to a TensorArray.
    flow_in: A `Tensor` of type `float32`.
      A float scalar that enforces proper chaining of operations.
    dtype: A `tf.DType`. The type of the elem that is returned.
    element_shape_except0: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.
      The expected shape of an element, if known,
      excluding the first dimension. Used to validate the shapes of
      TensorArray elements. If this shape is not fully specified, concatenating
      zero-size TensorArrays is an error.
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (value, lengths).

    value: A `Tensor` of type `dtype`.
    lengths: A `Tensor` of type `int64`.
  """
  ...

TensorArrayConcatV3 = ...
def tensor_array_concat_v3_eager_fallback(handle: Annotated[Any, _atypes.Resource], flow_in: Annotated[Any, _atypes.Float32], dtype: TV_TensorArrayConcatV3_dtype, element_shape_except0, name, ctx): # -> TensorArrayConcatV3:
  ...

TV_TensorArrayGather_dtype = TypeVar("TV_TensorArrayGather_dtype", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array_gather(handle: Annotated[Any, _atypes.String], indices: Annotated[Any, _atypes.Int32], flow_in: Annotated[Any, _atypes.Float32], dtype: TV_TensorArrayGather_dtype, element_shape=..., name=...) -> Annotated[Any, TV_TensorArrayGather_dtype]:
  r"""TODO: add doc.

  Args:
    handle: A `Tensor` of type mutable `string`.
    indices: A `Tensor` of type `int32`.
    flow_in: A `Tensor` of type `float32`.
    dtype: A `tf.DType`.
    element_shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `dtype`.
  """
  ...

TensorArrayGather = ...
def tensor_array_gather_eager_fallback(handle: Annotated[Any, _atypes.String], indices: Annotated[Any, _atypes.Int32], flow_in: Annotated[Any, _atypes.Float32], dtype: TV_TensorArrayGather_dtype, element_shape, name, ctx) -> Annotated[Any, TV_TensorArrayGather_dtype]:
  ...

TV_TensorArrayGatherV2_dtype = TypeVar("TV_TensorArrayGatherV2_dtype", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array_gather_v2(handle: Annotated[Any, _atypes.String], indices: Annotated[Any, _atypes.Int32], flow_in: Annotated[Any, _atypes.Float32], dtype: TV_TensorArrayGatherV2_dtype, element_shape=..., name=...) -> Annotated[Any, TV_TensorArrayGatherV2_dtype]:
  r"""Deprecated. Use TensorArrayGatherV3

  Args:
    handle: A `Tensor` of type `string`.
    indices: A `Tensor` of type `int32`.
    flow_in: A `Tensor` of type `float32`.
    dtype: A `tf.DType`.
    element_shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `dtype`.
  """
  ...

TensorArrayGatherV2 = ...
def tensor_array_gather_v2_eager_fallback(handle: Annotated[Any, _atypes.String], indices: Annotated[Any, _atypes.Int32], flow_in: Annotated[Any, _atypes.Float32], dtype: TV_TensorArrayGatherV2_dtype, element_shape, name, ctx) -> Annotated[Any, TV_TensorArrayGatherV2_dtype]:
  ...

TV_TensorArrayGatherV3_dtype = TypeVar("TV_TensorArrayGatherV3_dtype", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array_gather_v3(handle: Annotated[Any, _atypes.Resource], indices: Annotated[Any, _atypes.Int32], flow_in: Annotated[Any, _atypes.Float32], dtype: TV_TensorArrayGatherV3_dtype, element_shape=..., name=...) -> Annotated[Any, TV_TensorArrayGatherV3_dtype]:
  r"""Gather specific elements from the TensorArray into output `value`.

  All elements selected by `indices` must have the same shape.

  Args:
    handle: A `Tensor` of type `resource`. The handle to a TensorArray.
    indices: A `Tensor` of type `int32`.
      The locations in the TensorArray from which to read tensor elements.
    flow_in: A `Tensor` of type `float32`.
      A float scalar that enforces proper chaining of operations.
    dtype: A `tf.DType`. The type of the elem that is returned.
    element_shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.
      The expected shape of an element, if known. Used to
      validate the shapes of TensorArray elements. If this shape is not
      fully specified, gathering zero-size TensorArrays is an error.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `dtype`.
  """
  ...

TensorArrayGatherV3 = ...
def tensor_array_gather_v3_eager_fallback(handle: Annotated[Any, _atypes.Resource], indices: Annotated[Any, _atypes.Int32], flow_in: Annotated[Any, _atypes.Float32], dtype: TV_TensorArrayGatherV3_dtype, element_shape, name, ctx) -> Annotated[Any, TV_TensorArrayGatherV3_dtype]:
  ...

def tensor_array_grad(handle: Annotated[Any, _atypes.String], flow_in: Annotated[Any, _atypes.Float32], source: str, name=...) -> Annotated[Any, _atypes.String]:
  r"""TODO: add doc.

  Args:
    handle: A `Tensor` of type `string`.
    flow_in: A `Tensor` of type `float32`.
    source: A `string`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type mutable `string`.
  """
  ...

TensorArrayGrad = ...
def tensor_array_grad_eager_fallback(handle: Annotated[Any, _atypes.String], flow_in: Annotated[Any, _atypes.Float32], source: str, name, ctx) -> Annotated[Any, _atypes.String]:
  ...

def tensor_array_grad_v2(handle: Annotated[Any, _atypes.String], flow_in: Annotated[Any, _atypes.Float32], source: str, name=...) -> Annotated[Any, _atypes.String]:
  r"""Deprecated. Use TensorArrayGradV3

  Args:
    handle: A `Tensor` of type `string`.
    flow_in: A `Tensor` of type `float32`.
    source: A `string`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `string`.
  """
  ...

TensorArrayGradV2 = ...
def tensor_array_grad_v2_eager_fallback(handle: Annotated[Any, _atypes.String], flow_in: Annotated[Any, _atypes.Float32], source: str, name, ctx) -> Annotated[Any, _atypes.String]:
  ...

_TensorArrayGradV3Output = ...
def tensor_array_grad_v3(handle: Annotated[Any, _atypes.Resource], flow_in: Annotated[Any, _atypes.Float32], source: str, name=...): # -> TensorArrayGradV3:
  r"""Creates a TensorArray for storing the gradients of values in the given handle.

  If the given TensorArray gradient already exists, returns a reference to it.

  Locks the size of the original TensorArray by disabling its dynamic size flag.

  **A note about the input flow_in:**

  The handle flow_in forces the execution of the gradient lookup to occur
  only after certain other operations have occurred.  For example, when
  the forward TensorArray is dynamically sized, writes to this TensorArray
  may resize the object.  The gradient TensorArray is statically sized based
  on the size of the forward TensorArray when this operation executes.
  Furthermore, the size of the forward TensorArray is frozen by this call.
  As a result, the flow is used to ensure that the call to generate the gradient
  TensorArray only happens after all writes are executed.

  In the case of dynamically sized TensorArrays, gradient computation should
  only be performed on read operations that have themselves been chained via
  flow to occur only after all writes have executed. That way the final size
  of the forward TensorArray is known when this operation is called.

  **A note about the source attribute:**

  TensorArray gradient calls use an accumulator TensorArray object.  If
  multiple gradients are calculated and run in the same session, the multiple
  gradient nodes may accidentally flow through the same accumulator TensorArray.
  This double counts and generally breaks the TensorArray gradient flow.

  The solution is to identify which gradient call this particular
  TensorArray gradient is being called in.  This is performed by identifying
  a unique string (e.g. "gradients", "gradients_1", ...) from the input
  gradient Tensor's name.  This string is used as a suffix when creating
  the TensorArray gradient object here (the attribute `source`).

  The attribute `source` is added as a suffix to the forward TensorArray's
  name when performing the creation / lookup, so that each separate gradient
  calculation gets its own TensorArray accumulator.

  Args:
    handle: A `Tensor` of type `resource`.
      The handle to the forward TensorArray.
    flow_in: A `Tensor` of type `float32`.
      A float scalar that enforces proper chaining of operations.
    source: A `string`.
      The gradient source string, used to decide which gradient TensorArray
      to return.
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (grad_handle, flow_out).

    grad_handle: A `Tensor` of type `resource`.
    flow_out: A `Tensor` of type `float32`.
  """
  ...

TensorArrayGradV3 = ...
def tensor_array_grad_v3_eager_fallback(handle: Annotated[Any, _atypes.Resource], flow_in: Annotated[Any, _atypes.Float32], source: str, name, ctx): # -> TensorArrayGradV3:
  ...

_TensorArrayGradWithShapeOutput = ...
def tensor_array_grad_with_shape(handle: Annotated[Any, _atypes.Resource], flow_in: Annotated[Any, _atypes.Float32], shape_to_prepend: Annotated[Any, _atypes.Int32], source: str, name=...): # -> TensorArrayGradWithShape:
  r"""Creates a TensorArray for storing multiple gradients of values in the given handle.

  Similar to TensorArrayGradV3. However it creates an accumulator with an
  expanded shape compared to the input TensorArray whose gradient is being
  computed. This enables multiple gradients for the same TensorArray to be
  calculated using the same accumulator.

  Args:
    handle: A `Tensor` of type `resource`.
      The handle to the forward TensorArray.
    flow_in: A `Tensor` of type `float32`.
      A float scalar that enforces proper chaining of operations.
    shape_to_prepend: A `Tensor` of type `int32`.
      An int32 vector representing a shape. Elements in the gradient accumulator will
      have shape which is this shape_to_prepend value concatenated with shape of the
      elements in the TensorArray corresponding to the input handle.
    source: A `string`.
      The gradient source string, used to decide which gradient TensorArray
      to return.
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (grad_handle, flow_out).

    grad_handle: A `Tensor` of type `resource`.
    flow_out: A `Tensor` of type `float32`.
  """
  ...

TensorArrayGradWithShape = ...
def tensor_array_grad_with_shape_eager_fallback(handle: Annotated[Any, _atypes.Resource], flow_in: Annotated[Any, _atypes.Float32], shape_to_prepend: Annotated[Any, _atypes.Int32], source: str, name, ctx): # -> TensorArrayGradWithShape:
  ...

TV_TensorArrayPack_dtype = TypeVar("TV_TensorArrayPack_dtype", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array_pack(handle: Annotated[Any, _atypes.String], flow_in: Annotated[Any, _atypes.Float32], dtype: TV_TensorArrayPack_dtype, element_shape=..., name=...) -> Annotated[Any, TV_TensorArrayPack_dtype]:
  r"""TODO: add doc.

  Args:
    handle: A `Tensor` of type mutable `string`.
    flow_in: A `Tensor` of type `float32`.
    dtype: A `tf.DType`.
    element_shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `dtype`.
  """
  ...

TensorArrayPack = ...
def tensor_array_pack_eager_fallback(handle: Annotated[Any, _atypes.String], flow_in: Annotated[Any, _atypes.Float32], dtype: TV_TensorArrayPack_dtype, element_shape, name, ctx) -> Annotated[Any, TV_TensorArrayPack_dtype]:
  ...

TV_TensorArrayRead_dtype = TypeVar("TV_TensorArrayRead_dtype", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array_read(handle: Annotated[Any, _atypes.String], index: Annotated[Any, _atypes.Int32], flow_in: Annotated[Any, _atypes.Float32], dtype: TV_TensorArrayRead_dtype, name=...) -> Annotated[Any, TV_TensorArrayRead_dtype]:
  r"""TODO: add doc.

  Args:
    handle: A `Tensor` of type mutable `string`.
    index: A `Tensor` of type `int32`.
    flow_in: A `Tensor` of type `float32`.
    dtype: A `tf.DType`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `dtype`.
  """
  ...

TensorArrayRead = ...
def tensor_array_read_eager_fallback(handle: Annotated[Any, _atypes.String], index: Annotated[Any, _atypes.Int32], flow_in: Annotated[Any, _atypes.Float32], dtype: TV_TensorArrayRead_dtype, name, ctx) -> Annotated[Any, TV_TensorArrayRead_dtype]:
  ...

TV_TensorArrayReadV2_dtype = TypeVar("TV_TensorArrayReadV2_dtype", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array_read_v2(handle: Annotated[Any, _atypes.String], index: Annotated[Any, _atypes.Int32], flow_in: Annotated[Any, _atypes.Float32], dtype: TV_TensorArrayReadV2_dtype, name=...) -> Annotated[Any, TV_TensorArrayReadV2_dtype]:
  r"""Deprecated. Use TensorArrayReadV3

  Args:
    handle: A `Tensor` of type `string`.
    index: A `Tensor` of type `int32`.
    flow_in: A `Tensor` of type `float32`.
    dtype: A `tf.DType`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `dtype`.
  """
  ...

TensorArrayReadV2 = ...
def tensor_array_read_v2_eager_fallback(handle: Annotated[Any, _atypes.String], index: Annotated[Any, _atypes.Int32], flow_in: Annotated[Any, _atypes.Float32], dtype: TV_TensorArrayReadV2_dtype, name, ctx) -> Annotated[Any, TV_TensorArrayReadV2_dtype]:
  ...

TV_TensorArrayReadV3_dtype = TypeVar("TV_TensorArrayReadV3_dtype", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array_read_v3(handle: Annotated[Any, _atypes.Resource], index: Annotated[Any, _atypes.Int32], flow_in: Annotated[Any, _atypes.Float32], dtype: TV_TensorArrayReadV3_dtype, name=...) -> Annotated[Any, TV_TensorArrayReadV3_dtype]:
  r"""Read an element from the TensorArray into output `value`.

  Args:
    handle: A `Tensor` of type `resource`. The handle to a TensorArray.
    index: A `Tensor` of type `int32`.
    flow_in: A `Tensor` of type `float32`.
      A float scalar that enforces proper chaining of operations.
    dtype: A `tf.DType`. The type of the elem that is returned.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `dtype`.
  """
  ...

TensorArrayReadV3 = ...
def tensor_array_read_v3_eager_fallback(handle: Annotated[Any, _atypes.Resource], index: Annotated[Any, _atypes.Int32], flow_in: Annotated[Any, _atypes.Float32], dtype: TV_TensorArrayReadV3_dtype, name, ctx) -> Annotated[Any, TV_TensorArrayReadV3_dtype]:
  ...

TV_TensorArrayScatter_T = TypeVar("TV_TensorArrayScatter_T", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array_scatter(handle: Annotated[Any, _atypes.String], indices: Annotated[Any, _atypes.Int32], value: Annotated[Any, TV_TensorArrayScatter_T], flow_in: Annotated[Any, _atypes.Float32], name=...) -> Annotated[Any, _atypes.Float32]:
  r"""TODO: add doc.

  Args:
    handle: A `Tensor` of type mutable `string`.
    indices: A `Tensor` of type `int32`.
    value: A `Tensor`.
    flow_in: A `Tensor` of type `float32`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `float32`.
  """
  ...

TensorArrayScatter = ...
def tensor_array_scatter_eager_fallback(handle: Annotated[Any, _atypes.String], indices: Annotated[Any, _atypes.Int32], value: Annotated[Any, TV_TensorArrayScatter_T], flow_in: Annotated[Any, _atypes.Float32], name, ctx) -> Annotated[Any, _atypes.Float32]:
  ...

TV_TensorArrayScatterV2_T = TypeVar("TV_TensorArrayScatterV2_T", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array_scatter_v2(handle: Annotated[Any, _atypes.String], indices: Annotated[Any, _atypes.Int32], value: Annotated[Any, TV_TensorArrayScatterV2_T], flow_in: Annotated[Any, _atypes.Float32], name=...) -> Annotated[Any, _atypes.Float32]:
  r"""Deprecated. Use TensorArrayScatterV3

  Args:
    handle: A `Tensor` of type `string`.
    indices: A `Tensor` of type `int32`.
    value: A `Tensor`.
    flow_in: A `Tensor` of type `float32`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `float32`.
  """
  ...

TensorArrayScatterV2 = ...
def tensor_array_scatter_v2_eager_fallback(handle: Annotated[Any, _atypes.String], indices: Annotated[Any, _atypes.Int32], value: Annotated[Any, TV_TensorArrayScatterV2_T], flow_in: Annotated[Any, _atypes.Float32], name, ctx) -> Annotated[Any, _atypes.Float32]:
  ...

TV_TensorArrayScatterV3_T = TypeVar("TV_TensorArrayScatterV3_T", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array_scatter_v3(handle: Annotated[Any, _atypes.Resource], indices: Annotated[Any, _atypes.Int32], value: Annotated[Any, TV_TensorArrayScatterV3_T], flow_in: Annotated[Any, _atypes.Float32], name=...) -> Annotated[Any, _atypes.Float32]:
  r"""Scatter the data from the input value into specific TensorArray elements.

  `indices` must be a vector, its length must match the first dim of `value`.

  Args:
    handle: A `Tensor` of type `resource`. The handle to a TensorArray.
    indices: A `Tensor` of type `int32`.
      The locations at which to write the tensor elements.
    value: A `Tensor`. The concatenated tensor to write to the TensorArray.
    flow_in: A `Tensor` of type `float32`.
      A float scalar that enforces proper chaining of operations.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `float32`.
  """
  ...

TensorArrayScatterV3 = ...
def tensor_array_scatter_v3_eager_fallback(handle: Annotated[Any, _atypes.Resource], indices: Annotated[Any, _atypes.Int32], value: Annotated[Any, TV_TensorArrayScatterV3_T], flow_in: Annotated[Any, _atypes.Float32], name, ctx) -> Annotated[Any, _atypes.Float32]:
  ...

def tensor_array_size(handle: Annotated[Any, _atypes.String], flow_in: Annotated[Any, _atypes.Float32], name=...) -> Annotated[Any, _atypes.Int32]:
  r"""TODO: add doc.

  Args:
    handle: A `Tensor` of type mutable `string`.
    flow_in: A `Tensor` of type `float32`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int32`.
  """
  ...

TensorArraySize = ...
def tensor_array_size_eager_fallback(handle: Annotated[Any, _atypes.String], flow_in: Annotated[Any, _atypes.Float32], name, ctx) -> Annotated[Any, _atypes.Int32]:
  ...

def tensor_array_size_v2(handle: Annotated[Any, _atypes.String], flow_in: Annotated[Any, _atypes.Float32], name=...) -> Annotated[Any, _atypes.Int32]:
  r"""Deprecated. Use TensorArraySizeV3

  Args:
    handle: A `Tensor` of type `string`.
    flow_in: A `Tensor` of type `float32`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int32`.
  """
  ...

TensorArraySizeV2 = ...
def tensor_array_size_v2_eager_fallback(handle: Annotated[Any, _atypes.String], flow_in: Annotated[Any, _atypes.Float32], name, ctx) -> Annotated[Any, _atypes.Int32]:
  ...

def tensor_array_size_v3(handle: Annotated[Any, _atypes.Resource], flow_in: Annotated[Any, _atypes.Float32], name=...) -> Annotated[Any, _atypes.Int32]:
  r"""Get the current size of the TensorArray.

  Args:
    handle: A `Tensor` of type `resource`.
      The handle to a TensorArray (output of TensorArray or TensorArrayGrad).
    flow_in: A `Tensor` of type `float32`.
      A float scalar that enforces proper chaining of operations.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int32`.
  """
  ...

TensorArraySizeV3 = ...
def tensor_array_size_v3_eager_fallback(handle: Annotated[Any, _atypes.Resource], flow_in: Annotated[Any, _atypes.Float32], name, ctx) -> Annotated[Any, _atypes.Int32]:
  ...

TV_TensorArraySplit_T = TypeVar("TV_TensorArraySplit_T", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array_split(handle: Annotated[Any, _atypes.String], value: Annotated[Any, TV_TensorArraySplit_T], lengths: Annotated[Any, _atypes.Int64], flow_in: Annotated[Any, _atypes.Float32], name=...) -> Annotated[Any, _atypes.Float32]:
  r"""TODO: add doc.

  Args:
    handle: A `Tensor` of type mutable `string`.
    value: A `Tensor`.
    lengths: A `Tensor` of type `int64`.
    flow_in: A `Tensor` of type `float32`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `float32`.
  """
  ...

TensorArraySplit = ...
def tensor_array_split_eager_fallback(handle: Annotated[Any, _atypes.String], value: Annotated[Any, TV_TensorArraySplit_T], lengths: Annotated[Any, _atypes.Int64], flow_in: Annotated[Any, _atypes.Float32], name, ctx) -> Annotated[Any, _atypes.Float32]:
  ...

TV_TensorArraySplitV2_T = TypeVar("TV_TensorArraySplitV2_T", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array_split_v2(handle: Annotated[Any, _atypes.String], value: Annotated[Any, TV_TensorArraySplitV2_T], lengths: Annotated[Any, _atypes.Int64], flow_in: Annotated[Any, _atypes.Float32], name=...) -> Annotated[Any, _atypes.Float32]:
  r"""Deprecated. Use TensorArraySplitV3

  Args:
    handle: A `Tensor` of type `string`.
    value: A `Tensor`.
    lengths: A `Tensor` of type `int64`.
    flow_in: A `Tensor` of type `float32`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `float32`.
  """
  ...

TensorArraySplitV2 = ...
def tensor_array_split_v2_eager_fallback(handle: Annotated[Any, _atypes.String], value: Annotated[Any, TV_TensorArraySplitV2_T], lengths: Annotated[Any, _atypes.Int64], flow_in: Annotated[Any, _atypes.Float32], name, ctx) -> Annotated[Any, _atypes.Float32]:
  ...

TV_TensorArraySplitV3_T = TypeVar("TV_TensorArraySplitV3_T", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array_split_v3(handle: Annotated[Any, _atypes.Resource], value: Annotated[Any, TV_TensorArraySplitV3_T], lengths: Annotated[Any, _atypes.Int64], flow_in: Annotated[Any, _atypes.Float32], name=...) -> Annotated[Any, _atypes.Float32]:
  r"""Split the data from the input value into TensorArray elements.

  Assuming that `lengths` takes on values

    ```
    (n0, n1, ..., n(T-1))
    ```

  and that `value` has shape

    ```
    (n0 + n1 + ... + n(T-1) x d0 x d1 x ...),
    ```

  this splits values into a TensorArray with T tensors.

  TensorArray index t will be the subtensor of values with starting position

    ```
    (n0 + n1 + ... + n(t-1), 0, 0, ...)
    ```

  and having size

    ```
    nt x d0 x d1 x ...
    ```

  Args:
    handle: A `Tensor` of type `resource`. The handle to a TensorArray.
    value: A `Tensor`. The concatenated tensor to write to the TensorArray.
    lengths: A `Tensor` of type `int64`.
      The vector of lengths, how to split the rows of value into the
      TensorArray.
    flow_in: A `Tensor` of type `float32`.
      A float scalar that enforces proper chaining of operations.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `float32`.
  """
  ...

TensorArraySplitV3 = ...
def tensor_array_split_v3_eager_fallback(handle: Annotated[Any, _atypes.Resource], value: Annotated[Any, TV_TensorArraySplitV3_T], lengths: Annotated[Any, _atypes.Int64], flow_in: Annotated[Any, _atypes.Float32], name, ctx) -> Annotated[Any, _atypes.Float32]:
  ...

TV_TensorArrayUnpack_T = TypeVar("TV_TensorArrayUnpack_T", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array_unpack(handle: Annotated[Any, _atypes.String], value: Annotated[Any, TV_TensorArrayUnpack_T], flow_in: Annotated[Any, _atypes.Float32], name=...) -> Annotated[Any, _atypes.Float32]:
  r"""TODO: add doc.

  Args:
    handle: A `Tensor` of type mutable `string`.
    value: A `Tensor`.
    flow_in: A `Tensor` of type `float32`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `float32`.
  """
  ...

TensorArrayUnpack = ...
def tensor_array_unpack_eager_fallback(handle: Annotated[Any, _atypes.String], value: Annotated[Any, TV_TensorArrayUnpack_T], flow_in: Annotated[Any, _atypes.Float32], name, ctx) -> Annotated[Any, _atypes.Float32]:
  ...

TV_TensorArrayV2_dtype = TypeVar("TV_TensorArrayV2_dtype", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array_v2(size: Annotated[Any, _atypes.Int32], dtype: TV_TensorArrayV2_dtype, element_shape=..., dynamic_size: bool = ..., clear_after_read: bool = ..., tensor_array_name: str = ..., name=...) -> Annotated[Any, _atypes.String]:
  r"""Deprecated. Use TensorArrayV3

  Args:
    size: A `Tensor` of type `int32`.
    dtype: A `tf.DType`.
    element_shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.
    dynamic_size: An optional `bool`. Defaults to `False`.
    clear_after_read: An optional `bool`. Defaults to `True`.
    tensor_array_name: An optional `string`. Defaults to `""`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `string`.
  """
  ...

TensorArrayV2 = ...
def tensor_array_v2_eager_fallback(size: Annotated[Any, _atypes.Int32], dtype: TV_TensorArrayV2_dtype, element_shape, dynamic_size: bool, clear_after_read: bool, tensor_array_name: str, name, ctx) -> Annotated[Any, _atypes.String]:
  ...

_TensorArrayV3Output = ...
TV_TensorArrayV3_dtype = TypeVar("TV_TensorArrayV3_dtype", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array_v3(size: Annotated[Any, _atypes.Int32], dtype: TV_TensorArrayV3_dtype, element_shape=..., dynamic_size: bool = ..., clear_after_read: bool = ..., identical_element_shapes: bool = ..., tensor_array_name: str = ..., name=...): # -> TensorArrayV3:
  r"""An array of Tensors of given size.

  Write data via Write and read via Read or Pack.

  Args:
    size: A `Tensor` of type `int32`. The size of the array.
    dtype: A `tf.DType`. The type of the elements on the tensor_array.
    element_shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.
      The expected shape of an element, if known. Used to
      validate the shapes of TensorArray elements. If this shape is not
      fully specified, gathering zero-size TensorArrays is an error.
    dynamic_size: An optional `bool`. Defaults to `False`.
      A boolean that determines whether writes to the TensorArray
      are allowed to grow the size.  By default, this is not allowed.
    clear_after_read: An optional `bool`. Defaults to `True`.
      If true (default), Tensors in the TensorArray are cleared
      after being read.  This disables multiple read semantics but allows early
      release of memory.
    identical_element_shapes: An optional `bool`. Defaults to `False`.
      If true (default is false), then all
      elements in the TensorArray will be expected to have identical shapes.
      This allows certain behaviors, like dynamically checking for
      consistent shapes on write, and being able to fill in properly
      shaped zero tensors on stack -- even if the element_shape attribute
      is not fully defined.
    tensor_array_name: An optional `string`. Defaults to `""`.
      Overrides the name used for the temporary tensor_array
      resource. Default value is the name of the 'TensorArray' op (which
      is guaranteed unique).
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (handle, flow).

    handle: A `Tensor` of type `resource`.
    flow: A `Tensor` of type `float32`.
  """
  ...

TensorArrayV3 = ...
def tensor_array_v3_eager_fallback(size: Annotated[Any, _atypes.Int32], dtype: TV_TensorArrayV3_dtype, element_shape, dynamic_size: bool, clear_after_read: bool, identical_element_shapes: bool, tensor_array_name: str, name, ctx): # -> TensorArrayV3:
  ...

TV_TensorArrayWrite_T = TypeVar("TV_TensorArrayWrite_T", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array_write(handle: Annotated[Any, _atypes.String], index: Annotated[Any, _atypes.Int32], value: Annotated[Any, TV_TensorArrayWrite_T], flow_in: Annotated[Any, _atypes.Float32], name=...) -> Annotated[Any, _atypes.Float32]:
  r"""TODO: add doc.

  Args:
    handle: A `Tensor` of type mutable `string`.
    index: A `Tensor` of type `int32`.
    value: A `Tensor`.
    flow_in: A `Tensor` of type `float32`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `float32`.
  """
  ...

TensorArrayWrite = ...
def tensor_array_write_eager_fallback(handle: Annotated[Any, _atypes.String], index: Annotated[Any, _atypes.Int32], value: Annotated[Any, TV_TensorArrayWrite_T], flow_in: Annotated[Any, _atypes.Float32], name, ctx) -> Annotated[Any, _atypes.Float32]:
  ...

TV_TensorArrayWriteV2_T = TypeVar("TV_TensorArrayWriteV2_T", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array_write_v2(handle: Annotated[Any, _atypes.String], index: Annotated[Any, _atypes.Int32], value: Annotated[Any, TV_TensorArrayWriteV2_T], flow_in: Annotated[Any, _atypes.Float32], name=...) -> Annotated[Any, _atypes.Float32]:
  r"""Deprecated. Use TensorArrayGradV3

  Args:
    handle: A `Tensor` of type `string`.
    index: A `Tensor` of type `int32`.
    value: A `Tensor`.
    flow_in: A `Tensor` of type `float32`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `float32`.
  """
  ...

TensorArrayWriteV2 = ...
def tensor_array_write_v2_eager_fallback(handle: Annotated[Any, _atypes.String], index: Annotated[Any, _atypes.Int32], value: Annotated[Any, TV_TensorArrayWriteV2_T], flow_in: Annotated[Any, _atypes.Float32], name, ctx) -> Annotated[Any, _atypes.Float32]:
  ...

TV_TensorArrayWriteV3_T = TypeVar("TV_TensorArrayWriteV3_T", _atypes.BFloat16, _atypes.Bool, _atypes.Complex128, _atypes.Complex64, _atypes.Float16, _atypes.Float32, _atypes.Float64, _atypes.Float8e4m3fn, _atypes.Float8e5m2, _atypes.Half, _atypes.Int16, _atypes.Int32, _atypes.Int4, _atypes.Int64, _atypes.Int8, _atypes.QInt16, _atypes.QInt32, _atypes.QInt8, _atypes.QUInt16, _atypes.QUInt8, _atypes.Resource, _atypes.String, _atypes.UInt16, _atypes.UInt32, _atypes.UInt4, _atypes.UInt64, _atypes.UInt8, _atypes.Variant)
def tensor_array_write_v3(handle: Annotated[Any, _atypes.Resource], index: Annotated[Any, _atypes.Int32], value: Annotated[Any, TV_TensorArrayWriteV3_T], flow_in: Annotated[Any, _atypes.Float32], name=...) -> Annotated[Any, _atypes.Float32]:
  r"""Push an element onto the tensor_array.

  Args:
    handle: A `Tensor` of type `resource`. The handle to a TensorArray.
    index: A `Tensor` of type `int32`.
      The position to write to inside the TensorArray.
    value: A `Tensor`. The tensor to write to the TensorArray.
    flow_in: A `Tensor` of type `float32`.
      A float scalar that enforces proper chaining of operations.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `float32`.
  """
  ...

TensorArrayWriteV3 = ...
def tensor_array_write_v3_eager_fallback(handle: Annotated[Any, _atypes.Resource], index: Annotated[Any, _atypes.Int32], value: Annotated[Any, TV_TensorArrayWriteV3_T], flow_in: Annotated[Any, _atypes.Float32], name, ctx) -> Annotated[Any, _atypes.Float32]:
  ...

def unstage(dtypes, capacity: int = ..., memory_limit: int = ..., container: str = ..., shared_name: str = ..., name=...): # -> object | Operation | tuple[Any, ...] | list[Any]:
  r"""Op is similar to a lightweight Dequeue.

  The basic functionality is similar to dequeue with many fewer
  capabilities and options.  This Op is optimized for performance.

  Args:
    dtypes: A list of `tf.DTypes` that has length `>= 1`.
    capacity: An optional `int` that is `>= 0`. Defaults to `0`.
    memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
    container: An optional `string`. Defaults to `""`.
    shared_name: An optional `string`. Defaults to `""`.
    name: A name for the operation (optional).

  Returns:
    A list of `Tensor` objects of type `dtypes`.
  """
  ...

Unstage = ...
def unstage_eager_fallback(dtypes, capacity: int, memory_limit: int, container: str, shared_name: str, name, ctx): # -> object:
  ...

