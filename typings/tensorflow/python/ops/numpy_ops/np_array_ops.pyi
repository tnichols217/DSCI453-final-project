"""
This type stub file was generated by pyright.
"""

import enum
from tensorflow.python.ops.numpy_ops import np_utils
from tensorflow.python.util import tf_export

"""Common array methods."""
newaxis = ...
@tf_export.tf_export('experimental.numpy.empty', v1=[])
@np_utils.np_doc('empty')
def empty(shape, dtype=...): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.empty_like', v1=[])
@np_utils.np_doc('empty_like')
def empty_like(a, dtype=...): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.zeros', v1=[])
@np_utils.np_doc('zeros')
def zeros(shape, dtype=...): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.zeros_like', v1=[])
@np_utils.np_doc('zeros_like')
def zeros_like(a, dtype=...): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.ones', v1=[])
@np_utils.np_doc('ones')
def ones(shape, dtype=...): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.ones_like', v1=[])
@np_utils.np_doc('ones_like')
def ones_like(a, dtype=...): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.eye', v1=[])
@np_utils.np_doc('eye')
def eye(N, M=..., k=..., dtype=...): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.identity', v1=[])
@np_utils.np_doc('identity')
def identity(n, dtype=...): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.full', v1=[])
@np_utils.np_doc('full')
def full(shape, fill_value, dtype=...): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.full_like', v1=[])
@np_utils.np_doc_only('full_like')
def full_like(a, fill_value, dtype=..., order=..., subok=..., shape=...): # -> Any:
  """order, subok and shape arguments mustn't be changed."""
  ...

@tf_export.tf_export('experimental.numpy.array', v1=[])
@np_utils.np_doc_only('array')
def array(val, dtype=..., copy=..., ndmin=...): # -> defaultdict[Any, Any] | Any | list[Any] | object | Tensor | SparseTensor | IndexedSlices | SymbolicTensor | tuple[Any, ...] | None:
  """Since Tensors are immutable, a copy is made only if val is placed on a

  different device than the current one. Even if `copy` is False, a new Tensor
  may need to be built to satisfy `dtype` and `ndim`. This is used only if `val`
  is an ndarray or a Tensor.
  """
  ...

@tf_export.tf_export('experimental.numpy.asarray', v1=[])
@np_utils.np_doc('asarray')
def asarray(a, dtype=...): # -> ndarray | defaultdict[Any, Any] | Any | list[Any] | object | SparseTensor | IndexedSlices | SymbolicTensor | tuple[Any, ...] | None:
  ...

@tf_export.tf_export('experimental.numpy.asanyarray', v1=[])
@np_utils.np_doc('asanyarray')
def asanyarray(a, dtype=...): # -> ndarray | defaultdict[Any, Any] | Any | list[Any] | object | SparseTensor | IndexedSlices | SymbolicTensor | tuple[Any, ...] | None:
  ...

@tf_export.tf_export('experimental.numpy.ascontiguousarray', v1=[])
@np_utils.np_doc('ascontiguousarray')
def ascontiguousarray(a, dtype=...): # -> defaultdict[Any, Any] | Any | list[Any] | object | Tensor | SparseTensor | IndexedSlices | SymbolicTensor | tuple[Any, ...] | None:
  ...

@tf_export.tf_export('experimental.numpy.arange', v1=[])
@np_utils.np_doc('arange')
def arange(start, stop=..., step=..., dtype=...): # -> defaultdict[Any, Any] | Any | list[Any] | object | Tensor | SparseTensor | IndexedSlices | SymbolicTensor | tuple[Any, ...] | None:
  """Returns `step`-separated values in the range [start, stop).

  Args:
    start: Start of the interval. Included in the range.
    stop: End of the interval. If not specified, `start` is treated as 0 and
      `start` value is used as `stop`. If specified, it is not included in the
      range if `step` is integer. When `step` is floating point, it may or may
      not be included.
    step: The difference between 2 consecutive values in the output range. It is
      recommended to use `linspace` instead of using non-integer values for
      `step`.
    dtype: Optional. Type of the resulting ndarray. Could be a python type, a
      NumPy type or a TensorFlow `DType`. If not provided, the largest type of
      `start`, `stop`, `step` is used.

  Raises:
    ValueError: If step is zero.
  """
  ...

@tf_export.tf_export('experimental.numpy.diag', v1=[])
@np_utils.np_doc('diag')
def diag(v, k=...): # -> defaultdict[Any, Any] | Any | list[Any] | tuple[Any, ...] | None:
  """Raises an error if input is not 1- or 2-d."""
  ...

@tf_export.tf_export('experimental.numpy.diagonal', v1=[])
@np_utils.np_doc('diagonal')
def diagonal(a, offset=..., axis1=..., axis2=...): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.diagflat', v1=[])
@np_utils.np_doc('diagflat')
def diagflat(v, k=...): # -> defaultdict[Any, Any] | Any | list[Any] | tuple[Any, ...] | None:
  ...

@tf_export.tf_export('experimental.numpy.all', v1=[])
@np_utils.np_doc('all')
def all(a, axis=..., keepdims=...):
  ...

@tf_export.tf_export('experimental.numpy.any', v1=[])
@np_utils.np_doc('any')
def any(a, axis=..., keepdims=...):
  ...

@tf_export.tf_export('experimental.numpy.compress', v1=[])
@np_utils.np_doc('compress')
def compress(condition, a, axis=...): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.copy', v1=[])
@np_utils.np_doc('copy')
def copy(a): # -> defaultdict[Any, Any] | Any | list[Any] | object | Tensor | SparseTensor | IndexedSlices | SymbolicTensor | tuple[Any, ...] | None:
  ...

@tf_export.tf_export('experimental.numpy.cumprod', v1=[])
@np_utils.np_doc('cumprod')
def cumprod(a, axis=..., dtype=...):
  ...

@tf_export.tf_export('experimental.numpy.cumsum', v1=[])
@np_utils.np_doc('cumsum')
def cumsum(a, axis=..., dtype=...):
  ...

@tf_export.tf_export('experimental.numpy.imag', v1=[])
@np_utils.np_doc('imag')
def imag(val): # -> Any:
  ...

_TO_INT_ = ...
_TO_FLOAT = ...
@tf_export.tf_export('experimental.numpy.size', v1=[])
@np_utils.np_doc('size')
def size(x, axis=...): # -> SymbolicTensor | Operation | _EagerTensorBase | Any | Literal[1]:
  ...

@tf_export.tf_export('experimental.numpy.sum', v1=[])
@np_utils.np_doc('sum')
def sum(a, axis=..., dtype=..., keepdims=...):
  ...

@tf_export.tf_export('experimental.numpy.prod', v1=[])
@np_utils.np_doc('prod')
def prod(a, axis=..., dtype=..., keepdims=...):
  ...

@tf_export.tf_export('experimental.numpy.mean', v1=[])
@np_utils.np_doc('mean', unsupported_params=['out'])
def mean(a, axis=..., dtype=..., out=..., keepdims=...):
  ...

@tf_export.tf_export('experimental.numpy.amax', v1=[])
@np_utils.np_doc('amax', unsupported_params=['out'])
def amax(a, axis=..., out=..., keepdims=...):
  ...

@tf_export.tf_export('experimental.numpy.amin', v1=[])
@np_utils.np_doc('amin', unsupported_params=['out'])
def amin(a, axis=..., out=..., keepdims=...):
  ...

@tf_export.tf_export('experimental.numpy.var', v1=[])
@np_utils.np_doc('var')
def var(a, axis=..., dtype=..., out=..., ddof=..., keepdims=...): # -> Tensor | SparseTensor | IndexedSlices | SymbolicTensor:
  ...

@tf_export.tf_export('experimental.numpy.std', v1=[])
@np_utils.np_doc('std')
def std(a, axis=..., keepdims=...):
  ...

@tf_export.tf_export('experimental.numpy.ravel', v1=[])
@np_utils.np_doc('ravel')
def ravel(a): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.real', v1=[])
@np_utils.np_doc('real')
def real(val): # -> SymbolicTensor:
  ...

@tf_export.tf_export('experimental.numpy.repeat', v1=[])
@np_utils.np_doc('repeat')
def repeat(a, repeats, axis=...): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.around', v1=[])
@np_utils.np_doc('around')
def around(a, decimals=...):
  ...

@tf_export.tf_export('experimental.numpy.reshape', v1=[])
@np_utils.np_doc('reshape')
def reshape(a, newshape, order=...): # -> Any:
  """order argument can only b 'C' or 'F'."""
  ...

@tf_export.tf_export('experimental.numpy.expand_dims', v1=[])
@np_utils.np_doc('expand_dims')
def expand_dims(a, axis): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.squeeze', v1=[])
@np_utils.np_doc('squeeze')
def squeeze(a, axis=...): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.flatten', v1=[])
@np_utils.np_doc('flatten', link=np_utils.NoLink())
def flatten(a, order=...): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.transpose', v1=[])
@np_utils.np_doc('transpose')
def transpose(a, axes=...): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.swapaxes', v1=[])
@np_utils.np_doc('swapaxes')
def swapaxes(a, axis1, axis2): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.moveaxis', v1=[])
@np_utils.np_doc('moveaxis')
def moveaxis(a, source, destination): # -> Any:
  """Raises ValueError if source, destination not in (-ndim(a), ndim(a))."""
  ...

@tf_export.tf_export('experimental.numpy.pad', v1=[])
@np_utils.np_doc('pad')
def pad(array, pad_width, mode, **kwargs): # -> Any:
  """Only supports modes 'constant', 'reflect' and 'symmetric' currently."""
  ...

@tf_export.tf_export('experimental.numpy.take', v1=[])
@np_utils.np_doc('take')
def take(a, indices, axis=..., out=..., mode=...): # -> Any:
  """out argument is not supported, and default mode is clip."""
  ...

@tf_export.tf_export('experimental.numpy.where', v1=[])
@np_utils.np_doc_only('where')
def where(condition, x=..., y=...): # -> object | tuple[Any, ...] | list[Any] | Any:
  """Raises ValueError if exactly one of x or y is not None."""
  ...

@tf_export.tf_export('experimental.numpy.select', v1=[])
@np_utils.np_doc('select')
def select(condlist, choicelist, default=...): # -> ndarray | defaultdict[Any, Any] | Any | list[Any] | object | SparseTensor | IndexedSlices | SymbolicTensor | tuple[Any, ...] | None:
  ...

@tf_export.tf_export('experimental.numpy.shape', v1=[])
@np_utils.np_doc('shape', link=np_utils.Link('https://numpy.org/doc/1.18/reference/generated/numpy.shape.html'))
def shape(a): # -> TensorShape | Any:
  ...

@tf_export.tf_export('experimental.numpy.ndim', v1=[])
@np_utils.np_doc('ndim', link=np_utils.NoLink())
def ndim(a): # -> int | Any | None:
  ...

@tf_export.tf_export('experimental.numpy.isscalar', v1=[])
@np_utils.np_doc('isscalar')
def isscalar(num): # -> bool | Any:
  ...

@tf_export.tf_export('experimental.numpy.split', v1=[])
@np_utils.np_doc('split')
def split(ary, indices_or_sections, axis=...): # -> object | tuple[Any, ...] | list[Any]:
  ...

vsplit = ...
hsplit = ...
dsplit = ...
@tf_export.tf_export('experimental.numpy.broadcast_to', v1=[])
@np_utils.np_doc('broadcast_to')
def broadcast_to(array, shape): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.stack', v1=[])
@np_utils.np_doc('stack')
def stack(arrays, axis=...): # -> ndarray | defaultdict[Any, Any] | Any | list[Any] | object | SparseTensor | IndexedSlices | SymbolicTensor | tuple[Any, ...] | None:
  ...

@tf_export.tf_export('experimental.numpy.hstack', v1=[])
@np_utils.np_doc('hstack')
def hstack(tup): # -> defaultdict[Any, Any] | Any | list[Any] | tuple[Any, ...] | object | None:
  ...

@tf_export.tf_export('experimental.numpy.vstack', v1=[])
@np_utils.np_doc('vstack')
def vstack(tup): # -> defaultdict[Any, Any] | Any | list[Any] | object | None:
  ...

@tf_export.tf_export('experimental.numpy.dstack', v1=[])
@np_utils.np_doc('dstack')
def dstack(tup): # -> defaultdict[Any, Any] | Any | list[Any] | object | None:
  ...

@tf_export.tf_export('experimental.numpy.atleast_1d', v1=[])
@np_utils.np_doc('atleast_1d')
def atleast_1d(*arys): # -> ndarray | defaultdict[Any, Any] | Any | list[Any] | object | SparseTensor | IndexedSlices | SymbolicTensor | tuple[Any, ...] | list[ndarray | Any | defaultdict[Any, Any] | list[Any] | object | SparseTensor | IndexedSlices | SymbolicTensor | tuple[Any, ...] | None] | None:
  ...

@tf_export.tf_export('experimental.numpy.atleast_2d', v1=[])
@np_utils.np_doc('atleast_2d')
def atleast_2d(*arys): # -> ndarray | defaultdict[Any, Any] | Any | list[Any] | object | SparseTensor | IndexedSlices | SymbolicTensor | tuple[Any, ...] | list[ndarray | Any | defaultdict[Any, Any] | list[Any] | object | SparseTensor | IndexedSlices | SymbolicTensor | tuple[Any, ...] | None] | None:
  ...

@tf_export.tf_export('experimental.numpy.atleast_3d', v1=[])
@np_utils.np_doc('atleast_3d')
def atleast_3d(*arys): # -> ndarray | defaultdict[Any, Any] | Any | list[Any] | object | SparseTensor | IndexedSlices | SymbolicTensor | tuple[Any, ...] | list[ndarray | Any | defaultdict[Any, Any] | list[Any] | object | SparseTensor | IndexedSlices | SymbolicTensor | tuple[Any, ...] | None] | None:
  ...

@tf_export.tf_export('experimental.numpy.nonzero', v1=[])
@np_utils.np_doc('nonzero')
def nonzero(a): # -> object | tuple[Any, ...] | list[Any]:
  ...

@tf_export.tf_export('experimental.numpy.diag_indices', v1=[])
@np_utils.np_doc('diag_indices')
def diag_indices(n, ndim=...): # -> tuple[Any, ...]:
  ...

@tf_export.tf_export('experimental.numpy.tri', v1=[])
@np_utils.np_doc('tri')
def tri(N, M=..., k=..., dtype=...): # -> Any | Tensor | SparseTensor | IndexedSlices | SymbolicTensor:
  ...

@tf_export.tf_export('experimental.numpy.tril', v1=[])
@np_utils.np_doc('tril')
def tril(m, k=...): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.triu', v1=[])
@np_utils.np_doc('triu')
def triu(m, k=...): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.flip', v1=[])
@np_utils.np_doc('flip')
def flip(m, axis=...): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.flipud', v1=[])
@np_utils.np_doc('flipud')
def flipud(m): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.fliplr', v1=[])
@np_utils.np_doc('fliplr')
def fliplr(m): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.roll', v1=[])
@np_utils.np_doc('roll')
def roll(a, shift, axis=...): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.rot90', v1=[])
@np_utils.np_doc('rot90')
def rot90(m, k=..., axes=...): # -> Any:
  ...

@tf_export.tf_export('experimental.numpy.vander', v1=[])
@np_utils.np_doc('vander')
def vander(x, N=..., increasing=...):
  ...

@tf_export.tf_export('experimental.numpy.ix_', v1=[])
@np_utils.np_doc('ix_')
def ix_(*args): # -> list[Any]:
  ...

@tf_export.tf_export('experimental.numpy.broadcast_arrays', v1=[])
@np_utils.np_doc('broadcast_arrays')
def broadcast_arrays(*args, **kwargs): # -> tuple[()] | tuple[Any] | list[Any]:
  ...

@tf_export.tf_export('experimental.numpy.sign', v1=[])
@np_utils.np_doc_only('sign')
def sign(x, out=..., where=..., **kwargs): # -> Tensor | SparseTensor | IndexedSlices | SymbolicTensor:
  ...

@tf_export.tf_export('experimental.numpy.take_along_axis', v1=[])
@np_utils.np_doc('take_along_axis')
def take_along_axis(arr, indices, axis): # -> defaultdict[Any, Any] | Any | list[Any] | tuple[Any, ...] | None:
  ...

@tf_export.tf_export('experimental.numpy.max', v1=[])
@np_utils.np_doc('max', link=np_utils.AliasOf('amax'))
def max(a, axis=..., keepdims=...):
  ...

@tf_export.tf_export('experimental.numpy.min', v1=[])
@np_utils.np_doc('min', link=np_utils.AliasOf('amin'))
def min(a, axis=..., keepdims=...):
  ...

@tf_export.tf_export('experimental.numpy.round', v1=[])
@np_utils.np_doc('round', link=np_utils.AliasOf('around'))
def round(a, decimals=...):
  ...

_SLICE_ERROR = ...
class _UpdateMethod(enum.Enum):
  UPDATE = ...
  ADD = ...
  MIN = ...
  MAX = ...


