"""
This type stub file was generated by pyright.
"""

from tensorflow.python.keras.engine import training_utils_v1

"""Part of the Keras training engine related to Python generators of array data.
"""
def model_iteration(model, data, steps_per_epoch=..., epochs=..., verbose=..., callbacks=..., validation_data=..., validation_steps=..., validation_freq=..., class_weight=..., max_queue_size=..., workers=..., use_multiprocessing=..., shuffle=..., initial_epoch=..., mode=..., batch_size=..., steps_name=..., **kwargs):
  """Loop function for arrays of data with modes TRAIN/TEST/PREDICT.

  Args:
      model: Keras Model instance.
      data: Either a tuple of NumPy/Tensor inputs (i.e. `(x,)` or `(x, y)` or
        `(x, y, sample_weights)`) or a generator or
        `keras.utils.data_utils.Sequence` object or Eager Iterator or Dataset.
      steps_per_epoch: Total number of steps (batches of samples) before
        declaring one epoch finished and starting the next epoch. Ignored with
        the default value of `None`.
      epochs: Number of times to iterate over the data.
      verbose: 0, 1, or 2. Verbosity mode.
        0 = silent, 1 = progress bar, 2 = one line per epoch.
        Note that the progress bar is not particularly useful when
        logged to a file, so verbose=2 is recommended when not running
        interactively (eg, in a production environment).
      callbacks: List of callbacks to be called during training.
      validation_data: Either a tuple of NumPy/Tensor inputs (i.e. `(x,)` or
        `(x, y)` or `(x, y, sample_weights)`) or a generator or
        `keras.utils.data_utils.Sequence` object or Eager Iterator or Dataset.
      validation_steps: Total number of steps (batches of samples) before
        declaring validation finished.
      validation_freq: Only relevant if validation data is provided. Integer or
        `collections.abc.Container` instance (e.g. list, tuple, etc.). If an
        integer, specifies how many training epochs to run before a new
        validation run is performed, e.g. `validation_freq=2` runs
        validation every 2 epochs. If a Container, specifies the epochs on
        which to run validation, e.g. `validation_freq=[1, 2, 10]` runs
        validation at the end of the 1st, 2nd, and 10th epochs.
      class_weight: Dictionary mapping class indices to a weight for the class.
      max_queue_size: Integer. Maximum size for the generator queue. If
        unspecified, `max_queue_size` will default to 10.
      workers: Integer. Maximum number of processes to spin up when using
        process-based threading. If unspecified, `workers` will default to 1. If
        0, will execute the generator on the main thread.
      use_multiprocessing: Boolean. If `True`, use process-based threading. If
        unspecified, `use_multiprocessing` will default to `False`. Note that
        because this implementation relies on multiprocessing, you should not
        pass non-picklable arguments to the generator as they can't be passed
        easily to children processes.
      shuffle: Boolean. Whether to shuffle the order of the batches at the
        beginning of each epoch. Only used with instances of `Sequence`
        (`keras.utils.Sequence`). Has no effect when `steps_per_epoch` is not
        `None`.
      initial_epoch: Epoch at which to start training (useful for resuming a
        previous training run).
      mode: One of ModeKeys.TRAIN/ModeKeys.TEST/ModeKeys.PREDICT.
      batch_size: Integer batch size or None if unknown. Will only be used if
        `data` is in NumPy/Tensor format.
      steps_name: The string name of the steps argument, either `steps`,
        `validation_steps`, or `steps_per_epoch`. Only used for error message
        formatting.
      **kwargs: Additional arguments for backwards compatibility. `steps` is
        accepted as an alias for `steps_per_epoch`.

  Returns:
      - In TRAIN mode: `History` object.
      - In TEST mode: Evaluation metrics.
      - In PREDICT mode: Outputs of the Model called on inputs.

  Raises:
      ValueError: in case of invalid arguments.
  """
  ...

fit_generator = ...
evaluate_generator = ...
predict_generator = ...
def convert_to_generator_like(data, batch_size=..., steps_per_epoch=..., epochs=..., shuffle=...): # -> tuple[Sequence | tuple[Any, ...] | Any | IteratorBase, int | Any | None] | tuple[Iterator | OwnedIterator, Any | None] | tuple[Generator[Any | defaultdict[Any, Any] | list[Any] | None, Any, None], int]:
  """Make a generator out of NumPy or EagerTensor inputs.

  Args:
    data: Either a generator or `keras.utils.data_utils.Sequence` object or
      `Dataset`, `Iterator`, or a {1,2,3}-tuple of NumPy arrays or EagerTensors.
      If a tuple, the elements represent `(x, y, sample_weights)` and may be
      `None` or `[None]`.
    batch_size: Used when creating a generator out of tuples of NumPy arrays or
      EagerTensors.
    steps_per_epoch: Steps of the generator to run each epoch. If `None` the
      number of steps will be read from the data (for
      `keras.utils.data_utils.Sequence` types).
    epochs: Total number of epochs to run.
    shuffle: Whether the data should be shuffled.

  Returns:
    - Generator, `keras.utils.data_utils.Sequence`, or `Iterator`.

  Raises:
    - ValueError: If `batch_size` is not provided for NumPy or EagerTensor
      inputs.
  """
  ...

class GeneratorOrSequenceTrainingLoop(training_utils_v1.TrainingLoop):
  """Generator-like.

  Input is Python generator, or Sequence object.

  The difference between this class and `GeneratorLikeTrainingFunction` is that
  this class only handles inputs that with x, y and sample_weight fused into one
  param.
  """
  def fit(self, model, x=..., y=..., batch_size=..., epochs=..., verbose=..., callbacks=..., validation_split=..., validation_data=..., shuffle=..., class_weight=..., sample_weight=..., initial_epoch=..., steps_per_epoch=..., validation_steps=..., validation_freq=..., max_queue_size=..., workers=..., use_multiprocessing=...):
    ...
  
  def evaluate(self, model, x=..., y=..., batch_size=..., verbose=..., sample_weight=..., steps=..., callbacks=..., max_queue_size=..., workers=..., use_multiprocessing=...):
    ...
  
  def predict(self, model, x, batch_size=..., verbose=..., steps=..., callbacks=..., max_queue_size=..., workers=..., use_multiprocessing=...):
    ...
  


class EagerDatasetOrIteratorTrainingLoop(training_utils_v1.TrainingLoop):
  """A non-distributed Dataset or iterator in eager execution."""
  def fit(self, model, x=..., y=..., batch_size=..., epochs=..., verbose=..., callbacks=..., validation_split=..., validation_data=..., shuffle=..., class_weight=..., sample_weight=..., initial_epoch=..., steps_per_epoch=..., validation_steps=..., validation_freq=..., **kwargs):
    ...
  
  def evaluate(self, model, x=..., y=..., batch_size=..., verbose=..., sample_weight=..., steps=..., callbacks=..., **kwargs):
    ...
  
  def predict(self, model, x, batch_size=..., verbose=..., steps=..., callbacks=..., **kwargs):
    ...
  


class GeneratorLikeTrainingLoop(training_utils_v1.TrainingLoop):
  """TrainingLoop that handle inputs like python generator.

  This is the default handler for most of the input data types, includes
  symbolic tensors or Numpy array-like, Datasets and iterators in graph mode
  (since they generate symbolic tensors). This Function is used to handle model
  with `run_eagerly` = True.
  """
  def fit(self, model, x=..., y=..., batch_size=..., epochs=..., verbose=..., callbacks=..., validation_split=..., validation_data=..., shuffle=..., class_weight=..., sample_weight=..., initial_epoch=..., steps_per_epoch=..., validation_steps=..., validation_freq=..., **kwargs):
    ...
  
  def evaluate(self, model, x=..., y=..., batch_size=..., verbose=..., sample_weight=..., steps=..., callbacks=..., **kwargs):
    ...
  
  def predict(self, model, x, batch_size=..., verbose=..., steps=..., callbacks=..., **kwargs):
    ...
  


